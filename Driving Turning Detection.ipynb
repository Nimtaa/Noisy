{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import pandas\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from matplotlib.pyplot import figure\n",
    "import random\n",
    "from heapq import nlargest\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape = (200,10), return_sequences = True))\n",
    "model.add(LSTM(20, return_sequences= True))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# data = pandas.read_csv('./data/Learning/MyData/Turning/version2/data6_7_8_9.csv')\n",
    "data = pandas.read_csv('./data/Learning/MyData/Turning/rt_lt_classifier/data6_7.csv')\n",
    "\n",
    "\n",
    "X = data[['magneticHeading','gyroX','gyroY','gyroZ','Yaw','Roll','Pitch','accx','accy','accz']]\n",
    "target = data['TurnStatus']\n",
    "\n",
    "\n",
    "##### 5-fold corss validation\n",
    "\n",
    "##### fold 1 \n",
    "# X_train = X[:120000]\n",
    "# X_test = X[120000:135000]\n",
    "# y_train = target[:120000]\n",
    "# y_test = target[120000:135000]\n",
    "######\n",
    "\n",
    "##### fold 2\n",
    "# X_train= X[:135000]\n",
    "# X_test= X[135000:150000]\n",
    "# y_train= target[:135000]\n",
    "# y_test= target[135000:150000]\n",
    "######\n",
    "\n",
    "##### fold 3\n",
    "# X_train= X[:150000]\n",
    "# X_test= X[150000:165000]\n",
    "# y_train= target[:150000]\n",
    "# y_test= target[150000:165000]\n",
    "######\n",
    "\n",
    "##### fold 4\n",
    "# X_train = X[:165000]\n",
    "# X_test = X[165000:180000]\n",
    "# y_train = target[:165000]\n",
    "# y_test = target[165000:180000]\n",
    "######\n",
    "\n",
    "##### fold 5\n",
    "X_train = X[:180000]\n",
    "X_test = X[180000:]\n",
    "y_train = target[:180000]\n",
    "y_test = target[180000:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train = X[:40000]\n",
    "# y_train = target[:40000]\n",
    "\n",
    "# X_test = X[40000:]\n",
    "# y_test = target[40000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SmoothData(data):\n",
    "    size = data.shape[0] \n",
    "    dim = data.shape[1]\n",
    "    \n",
    "    smooth_data = np.zeros((size,dim))\n",
    "    \n",
    "    smooth_data[0] = data[0]\n",
    "    smooth_data[1] = data[1]\n",
    "    smooth_data[size-1] = data[size-1]\n",
    "    smooth_data[size-2] = data[size-2]\n",
    "    \n",
    "    for i in range(2, size-2):\n",
    "        smooth_data[i] = np.average([data[i], data[i-1], data[i+1]], axis=0)\n",
    "    return smooth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "X_train = np.array(X_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_train = SmoothData(X_train)\n",
    "X_test = SmoothData(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot  = []\n",
    "y_test_onehot = []\n",
    "for i in range(len(y_train)):\n",
    "    if(y_train[i]==0):\n",
    "        y_train_onehot.append(np.array([1,0,0]))\n",
    "    elif (y_train[i]==1):\n",
    "        y_train_onehot.append(np.array([0,1,0]))\n",
    "    elif(y_train[i]==2):\n",
    "        y_train_onehot.append(np.array([0,0,1]))\n",
    "#     elif(y_train[i]==3):\n",
    "#         y_train_onehot.append(np.array([0,0,0,1]))\n",
    "        \n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i]==0):\n",
    "        y_test_onehot.append(np.array([1,0,0]))\n",
    "    elif (y_test[i]==1):\n",
    "        y_test_onehot.append(np.array([0,1,0]))\n",
    "    elif (y_test[i]==2):\n",
    "        y_test_onehot.append(np.array([0,0,1]))\n",
    "#     elif (y_test[i]==3):\n",
    "#         y_test_onehot.append(np.array([0,0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### shuffle the train data to decorelate the training window segment\n",
    "X_train_shuffle = []\n",
    "y_train_shuffle = []\n",
    "shuffle_index = random.sample(range(0, 178800), 894)\n",
    "for i in shuffle_index:\n",
    "    X_train_shuffle.append (np.array([X_train[i:i+200]]).reshape(200,10))\n",
    "    y_train_shuffle.append (np.array([y_train_onehot[i:i+200]]).reshape(200,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(np.array(X_train_shuffle),\n",
    "                    np.array(y_train_shuffle),\n",
    "                    epochs=200,\n",
    "                    validation_data = (np.array([X_train[i:i+200] for i in range(178800,179800,50)]),\n",
    "                                      np.array([y_train_onehot[i:i+200] for i in range(178800,179800,50)])),\n",
    "                    batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(np.array(X_test[:16800]).reshape(84,200,10))\n",
    "results = results.reshape(16800,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_class = []\n",
    "for i in results:\n",
    "    if(np.argmax(i)==0):\n",
    "        result_class.append(0)\n",
    "    elif(np.argmax(i)==1):\n",
    "        result_class.append(1)\n",
    "    elif(np.argmax(i)==2):\n",
    "        result_class.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utitlity Functions\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Computing the energy (on y-axis)\n",
    "\n",
    "First, scale the accelerometer signal to the 9.8 \n",
    "Second, iterate list of events, calculate energy of the y-axis \n",
    "\"\"\"\n",
    "\n",
    "def Energy(data):\n",
    "    data = [abs(number) for number in data]\n",
    "    return np.sum(np.power(data,2))\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Scaling turn signal to m/s2\n",
    "\"\"\"\n",
    "def Scale(data):\n",
    "    scaled_data = data.copy()\n",
    "    for i in range(len(scaled_data)):\n",
    "        scaled_data[i] = scaled_data[i] * 9.8\n",
    "    return scaled_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating list of events and \n",
    "removing events with energy < 20 and duration lower than 30\n",
    "\n",
    "\"\"\"\n",
    "rt = 0\n",
    "lt = 0\n",
    "num_events = 0\n",
    "events = []\n",
    "freq = 100 \n",
    "scaled_data = Scale([X_test[i][8] for i in range(len(X_test))]) # ay\n",
    "\n",
    "for i in range(len(result_class)):\n",
    "    if(result_class[i]==1):\n",
    "        rt += 1\n",
    "    elif(result_class[i]==2):\n",
    "        lt += 1\n",
    "    else:\n",
    "        if(rt > 100 ):\n",
    "            signal = [abs ((scaled_data)[i]) for i in range(i-rt, i-1)]\n",
    "            energy = Energy(signal)\n",
    "            if(energy > 10):\n",
    "                events.append((\"rt\", i-rt, i-1, rt/freq))\n",
    "                print(num_events, \"- rt event,\" ,\"duration:\", rt/freq, \" tsteps\", \"init:\", i-rt ,\"end:\", i-1)\n",
    "                num_events += 1\n",
    "            rt = 0\n",
    "        elif(lt > 100):\n",
    "            signal = [abs ((scaled_data)[i]) for i in range(i-lt, i-1)]\n",
    "            energy = Energy(signal)\n",
    "            if(energy > 10):\n",
    "                events.append((\"lt\", i-lt, i-1, lt/freq))\n",
    "                print(num_events, \"- lt event,\" ,\"duration:\", lt/freq, \" tsteps\", \"init:\", i-lt ,\"end:\", i-1)\n",
    "                num_events += 1\n",
    "            lt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeIntensity(signal):\n",
    "    max_values = np.mean(nlargest(3, signal))\n",
    "    if(max_values > 0.1 and max_values < 0.2):\n",
    "        return 0\n",
    "    elif(max_values > 0.2 and max_values< 0.4):\n",
    "        return 1\n",
    "    elif(max_values > 0.4):\n",
    "        return 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assign intensity to each event \n",
    "0, 1, 2 --> Low, Medium, High\n",
    "thresholds:\n",
    "    0.98 = 0.1G\n",
    "    1.96 = 0.2G\n",
    "    3.92 = 0.4G\n",
    "\"\"\"    \n",
    "i = 0\n",
    "for e in events:\n",
    "    event_type, init, end, duration = e\n",
    "    signal = [abs(X_test)[i][8] for i in range(init, end)]\n",
    "    events[i] += (ComputeIntensity(signal),)\n",
    "    i +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "merging neighbour events\n",
    "\"\"\"\n",
    "duration = 0\n",
    "merge_index = 0\n",
    "deletion_index = []\n",
    "events.append(('',math.inf,math.inf,math.inf))\n",
    "\n",
    "for i in range(0,len(events)-1):\n",
    "    if(abs((events[i][2])-(events[i+1][1]))<11 and events[i][0]==events[i+1][0]):\n",
    "        duration +=1\n",
    "    else:\n",
    "        init = events[i-duration][1]\n",
    "        end = events[i][2]-1\n",
    "        events.append((events[i-duration][0], init, end, end-init, events[i-duration][4]))\n",
    "        deletion_index.append(np.arange(i-duration,i+1))\n",
    "        duration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.remove(('',math.inf,math.inf,math.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletion_index\n",
    "del events[0:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_class = np.zeros(len(X_test))\n",
    "for e in events:\n",
    "    event_type, init, end, duration, intensity = e\n",
    "    if(event_type!=''):\n",
    "        if(event_type ==\"rt\"):\n",
    "            result_class[init:end] = 1\n",
    "        elif(event_type==\"lt\"):\n",
    "            result_class[init:end] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "y_true = y_test.copy()\n",
    "y_pred = result_class.copy()\n",
    "classes = [0,1,2]\n",
    "confusion_matrix = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
    "confusion_matrix\n",
    "# fig = px.imshow(confusion_matrix)\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig =tools.make_subplots(rows=1,cols=1)\n",
    "\n",
    "result =  go.Scatter(\n",
    "    x = list(range(0,16800)),\n",
    "    y = result_class,\n",
    "    mode = 'lines',\n",
    "    name='model_result'\n",
    ")\n",
    "\n",
    "test =  go.Scatter(\n",
    "    x = list(range(0,16800)),\n",
    "    y = y_test,\n",
    "    mode = 'lines',\n",
    "    name='test'\n",
    ")\n",
    "\n",
    "fig.append_trace(result,1,1)\n",
    "fig.append_trace(test,1,1)\n",
    "\n",
    "\n",
    "fig['layout'].update(height=500, title = 'Turning Model Classification')\n",
    "\n",
    "\n",
    "py.offline.plot(fig, filename='fold5_turning_model_rt_lt_v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./Learning_model/Turning/rt_lt_cv/v2/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./Learning_model/Turning/rt_lt_cv/v2/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('./Learning_model/Turning/rt_lt_cv/v2/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./Learning_model/Turning/rt_lt_cv/v2/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "model = loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Calculator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Precision = True predicted turnings / total turnings\n",
    "Recall = True predicted turnings / total predicted turnings\n",
    "\n",
    "F1 = ( 2 . precision . recall ) / precision + recall\n",
    "performance = F1 * (IOU / #turning)\n",
    "\"\"\"\n",
    "\n",
    "fold1_precision = (7 / 5)\n",
    "fold1_recall = (7 / 10)\n",
    "fold1_f1 = (2 * fold1_precision * fold1_recall) / (fold1_precision + fold1_recall)\n",
    "fold1_iou =  (85.0/644 + 383.0/533 + 380.0/504 + 254.0/505 + 187.0/505 + 313.0/502 + 448.0/546) / 5\n",
    "fold1_perf = fold1_f1 * fold1_iou\n",
    "\n",
    "\n",
    "########\n",
    "fold2_precision = (5 / 5)\n",
    "fold2_recall = (5 / 10 )\n",
    "fold2_f1 = (2 * fold2_precision * fold2_recall) / (fold2_precision + fold2_recall)\n",
    "fold2_iou =(451.0/706 + 371.0/572 + 420.0/641 + 352.0/699 + 310.0/435) / 5\n",
    "fold2_perf = fold2_f1 * fold2_iou\n",
    "########\n",
    "\n",
    "########\n",
    "fold3_precision = (9/ 9)\n",
    "fold3_recall = (9 / 13 )\n",
    "fold3_f1 = (2 * fold3_precision * fold3_recall) / (fold3_precision + fold3_recall)\n",
    "fold3_iou = (304.0/569 + 621.0/730 + 416.0/472 + 116.0/379 + \n",
    "             124.0/379 +437.0 /650 + 286.0/380 + 395.0/521 + 251.0/465) / 9\n",
    "\n",
    "fold3_perf = fold3_f1 * fold3_iou\n",
    "########\n",
    "\n",
    "########\n",
    "fold4_precision = (4/ 3)\n",
    "fold4_recall = (4 / 8 )\n",
    "fold4_f1 = (2 * fold4_precision * fold4_recall) / (fold4_precision + fold4_recall)\n",
    "fold4_iou = (305.0/419 + 437.0/599 + 288.0/499 + 119.0/499 ) /3\n",
    "\n",
    "fold4_perf = fold4_f1 * fold4_iou\n",
    "########\n",
    "\n",
    "\n",
    "\n",
    "fold5_precision = (7 / 7)\n",
    "fold5_recall = (7 / 11 )\n",
    "fold5_f1 = (2 * fold5_precision * fold5_recall) / (fold5_precision + fold5_recall)\n",
    "fold5_iou = (396.0/527 +  325.0/529 + 599.0/734 + 406.0/476 + 451.0/468 + 391.0/438+ 411.0/476) / 7\n",
    "fold5_perf = fold5_f1 * fold5_iou\n",
    "########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Performance:\")\n",
    "print(fold1_perf,fold2_perf,fold3_perf,fold4_perf,fold5_perf)\n",
    "print(\"F1-score:\")\n",
    "print(fold1_f1,fold2_f1, fold3_f1,fold4_f1,fold5_f1)\n",
    "print(\"IOU:\")\n",
    "print(fold1_iou,fold2_iou, fold3_iou,fold4_iou,fold5_iou)\n",
    "\n",
    "print(\"performance mean:\", np.mean([fold1_perf, fold2_perf, fold3_perf, fold4_perf, fold5_perf]))\n",
    "print(\"f1-score mean:\", np.mean([fold1_f1,fold2_f1,fold3_f1, fold4_f1,fold5_f1]))\n",
    "print(\"iou mean:\", np.mean([fold1_iou,fold2_iou, fold3_iou,fold4_iou,fold5_iou]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =tools.make_subplots(rows=1,cols=2)\n",
    "\n",
    "f1 =  go.Bar(\n",
    "    x = list(range(5)),\n",
    "    y = [fold1_f1,fold2_f1,fold3_f1, fold4_f1,fold5_f1],\n",
    "    width=[0.5,0.5,0.5,0.5,0.5],\n",
    "    name='F1-score'\n",
    ")\n",
    "\n",
    "iou =  go.Bar(\n",
    "    x = list(range(5)),\n",
    "    y = [fold1_iou,fold2_iou, fold3_iou,fold4_iou,fold5_iou],\n",
    "    width=[0.5,0.5,0.5,0.5,0.5],\n",
    "    name='Intersection-Over-Union'\n",
    ")\n",
    "\n",
    "fig.append_trace(f1,1,1)\n",
    "fig.append_trace(iou,1,2)\n",
    "fig.update_traces(marker_line_width=1.5, opacity=0.75)\n",
    "\n",
    "fig['layout'].update(height=500, title = 'Turning Model Classification Accuracy')\n",
    "\n",
    "\n",
    "py.offline.plot(fig, filename='turning_model_rt_lt_v2_acc')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_env] *",
   "language": "python",
   "name": "conda-env-tensorflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
