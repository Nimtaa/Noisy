{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import pandas\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from matplotlib.pyplot import figure\n",
    "import random\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pandas.read_csv('./data/Learning/brake, acc/Train_Set.csv')\n",
    "# test = pandas.read_csv('./data/Learning/brake, acc/Test_Set.csv')\n",
    "data = pandas.read_csv('./data/Learning/MyData/version1/Train_Set.csv')\n",
    "test = pandas.read_csv('./data/Learning/MyData/version1/Test_Set.csv')\n",
    "# data = pandas.read_csv('./data/Learning/MyData/version2/Train_Set.csv')\n",
    "# test = pandas.read_csv('./data/Learning/MyData/version2/Test_Set.csv')\n",
    "# data = pandas.read_csv('./data/Learning/MyData/version3/Train_Set.csv')\n",
    "# test = pandas.read_csv('./data/Learning/MyData/version3/Test_Set.csv')\n",
    "\n",
    "\n",
    "# data = data[0:106092]\n",
    "# data = data[0:105658]\n",
    "x_train_set = data[['x','y','z']]\n",
    "# x_train_set = data[['x']]\n",
    "\n",
    "target = data['AccStatus']\n",
    "\n",
    "x_test_set = test[['x','y','z']]\n",
    "# x_test_set = test[['x']]\n",
    "y_test_set = test['AccStatus']\n",
    "\n",
    "\n",
    "x_train_set = np.array(x_train_set,dtype=float)          \n",
    "target = np.array(target,dtype=float)\n",
    "\n",
    "x_test_set =  np.array(x_test_set,dtype=float)\n",
    "y_test_set =  np.array(y_test_set,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34427"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SmoothData(data):\n",
    "    size = data.shape[0] \n",
    "    dim = data.shape[1]\n",
    "    \n",
    "    smooth_data = np.zeros((size,dim))\n",
    "    \n",
    "    smooth_data[0] = data[0]\n",
    "    smooth_data[1] = data[1]\n",
    "    smooth_data[size-1] = data[size-1]\n",
    "    smooth_data[size-2] = data[size-2]\n",
    "    \n",
    "    for i in range(2, size-2):\n",
    "        smooth_data[i] = np.average([data[i], data[i-1], data[i+1]], axis=0)\n",
    "    return smooth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_set = SmoothData(x_train_set)\n",
    "x_test_set = SmoothData(x_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_onehot  = []\n",
    "y_test_set_onehot = []\n",
    "for i in range(len(target)):\n",
    "    if(target[i]==0):\n",
    "        target_onehot.append(np.array([1,0,0]))\n",
    "    elif (target[i]==1):\n",
    "        target_onehot.append(np.array([0,1,0]))\n",
    "    elif(target[i]==2):\n",
    "        target_onehot.append(np.array([0,0,1]))\n",
    "        \n",
    "for i in range(len(y_test_set)):\n",
    "    if(y_test_set[i]==0):\n",
    "        y_test_set_onehot.append(np.array([1,0,0]))\n",
    "    elif (y_test_set[i]==1):\n",
    "        y_test_set_onehot.append(np.array([0,1,0]))\n",
    "    elif (y_test_set[i]==2):\n",
    "        y_test_set_onehot.append(np.array([0,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_x_train = []\n",
    "shuffle_target = []\n",
    "shuffle_index = random.sample(range(0, 139000), 2780)\n",
    "for i in shuffle_index:\n",
    "    shuffle_x_train.append (np.array([x_train_set[i:i+100]]).reshape(100,3))\n",
    "    shuffle_target.append (np.array([target_onehot[i:i+100]]).reshape(100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34427"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 100, 10)           560       \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100, 10)           840       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100, 3)            33        \n",
      "=================================================================\n",
      "Total params: 1,433\n",
      "Trainable params: 1,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape = (100,3), return_sequences = True))\n",
    "model.add(LSTM(10, return_sequences= True))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1040 samples, validate on 20 samples\n",
      "Epoch 1/200\n",
      "1040/1040 [==============================] - 8s 8ms/step - loss: 0.9931 - categorical_accuracy: 0.8731 - val_loss: 0.7982 - val_categorical_accuracy: 0.8890\n",
      "Epoch 2/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.5838 - categorical_accuracy: 0.9020 - val_loss: 0.5130 - val_categorical_accuracy: 0.8890\n",
      "Epoch 3/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.4454 - categorical_accuracy: 0.9020 - val_loss: 0.4865 - val_categorical_accuracy: 0.8890\n",
      "Epoch 4/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.4238 - categorical_accuracy: 0.9020 - val_loss: 0.4529 - val_categorical_accuracy: 0.8890\n",
      "Epoch 5/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.4064 - categorical_accuracy: 0.9020 - val_loss: 0.4342 - val_categorical_accuracy: 0.8890\n",
      "Epoch 6/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3918 - categorical_accuracy: 0.9020 - val_loss: 0.4159 - val_categorical_accuracy: 0.8890\n",
      "Epoch 7/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3811 - categorical_accuracy: 0.9020 - val_loss: 0.4080 - val_categorical_accuracy: 0.8890\n",
      "Epoch 8/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3739 - categorical_accuracy: 0.9020 - val_loss: 0.3899 - val_categorical_accuracy: 0.8890\n",
      "Epoch 9/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3681 - categorical_accuracy: 0.9019 - val_loss: 0.3897 - val_categorical_accuracy: 0.8890\n",
      "Epoch 10/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3630 - categorical_accuracy: 0.9026 - val_loss: 0.3981 - val_categorical_accuracy: 0.8917\n",
      "Epoch 11/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3599 - categorical_accuracy: 0.9042 - val_loss: 0.3749 - val_categorical_accuracy: 0.9038\n",
      "Epoch 12/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3546 - categorical_accuracy: 0.9078 - val_loss: 0.3477 - val_categorical_accuracy: 0.9072\n",
      "Epoch 13/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3521 - categorical_accuracy: 0.9085 - val_loss: 0.3538 - val_categorical_accuracy: 0.9065\n",
      "Epoch 14/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3472 - categorical_accuracy: 0.9089 - val_loss: 0.3646 - val_categorical_accuracy: 0.9070\n",
      "Epoch 15/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3439 - categorical_accuracy: 0.9100 - val_loss: 0.3836 - val_categorical_accuracy: 0.9060\n",
      "Epoch 16/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3399 - categorical_accuracy: 0.9101 - val_loss: 0.3906 - val_categorical_accuracy: 0.9062\n",
      "Epoch 17/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3362 - categorical_accuracy: 0.9105 - val_loss: 0.3873 - val_categorical_accuracy: 0.9070\n",
      "Epoch 18/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3341 - categorical_accuracy: 0.9110 - val_loss: 0.3293 - val_categorical_accuracy: 0.9100\n",
      "Epoch 19/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3289 - categorical_accuracy: 0.9113 - val_loss: 0.3540 - val_categorical_accuracy: 0.9097\n",
      "Epoch 20/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3259 - categorical_accuracy: 0.9110 - val_loss: 0.3554 - val_categorical_accuracy: 0.9100\n",
      "Epoch 21/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3244 - categorical_accuracy: 0.9111 - val_loss: 0.3431 - val_categorical_accuracy: 0.9110\n",
      "Epoch 22/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3181 - categorical_accuracy: 0.9113 - val_loss: 0.3902 - val_categorical_accuracy: 0.9090\n",
      "Epoch 23/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3165 - categorical_accuracy: 0.9113 - val_loss: 0.3245 - val_categorical_accuracy: 0.9125\n",
      "Epoch 24/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3145 - categorical_accuracy: 0.9106 - val_loss: 0.3393 - val_categorical_accuracy: 0.9112\n",
      "Epoch 25/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3118 - categorical_accuracy: 0.9109 - val_loss: 0.3370 - val_categorical_accuracy: 0.9118\n",
      "Epoch 26/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3068 - categorical_accuracy: 0.9108 - val_loss: 0.3983 - val_categorical_accuracy: 0.9093\n",
      "Epoch 27/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3026 - categorical_accuracy: 0.9115 - val_loss: 0.3486 - val_categorical_accuracy: 0.9103\n",
      "Epoch 28/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.3028 - categorical_accuracy: 0.9112 - val_loss: 0.3589 - val_categorical_accuracy: 0.9100\n",
      "Epoch 29/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2989 - categorical_accuracy: 0.9115 - val_loss: 0.3232 - val_categorical_accuracy: 0.9120\n",
      "Epoch 30/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2987 - categorical_accuracy: 0.9111 - val_loss: 0.3478 - val_categorical_accuracy: 0.9118\n",
      "Epoch 31/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2948 - categorical_accuracy: 0.9106 - val_loss: 0.3714 - val_categorical_accuracy: 0.9115\n",
      "Epoch 32/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2938 - categorical_accuracy: 0.9112 - val_loss: 0.3515 - val_categorical_accuracy: 0.9107\n",
      "Epoch 33/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2932 - categorical_accuracy: 0.9117 - val_loss: 0.3508 - val_categorical_accuracy: 0.9107\n",
      "Epoch 34/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2904 - categorical_accuracy: 0.9116 - val_loss: 0.4001 - val_categorical_accuracy: 0.9100\n",
      "Epoch 35/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2899 - categorical_accuracy: 0.9109 - val_loss: 0.3709 - val_categorical_accuracy: 0.9103\n",
      "Epoch 36/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2873 - categorical_accuracy: 0.9118 - val_loss: 0.3383 - val_categorical_accuracy: 0.9110\n",
      "Epoch 37/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2857 - categorical_accuracy: 0.9114 - val_loss: 0.4144 - val_categorical_accuracy: 0.9107\n",
      "Epoch 38/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2888 - categorical_accuracy: 0.9111 - val_loss: 0.3649 - val_categorical_accuracy: 0.9110\n",
      "Epoch 39/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2841 - categorical_accuracy: 0.9115 - val_loss: 0.3875 - val_categorical_accuracy: 0.9118\n",
      "Epoch 40/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2873 - categorical_accuracy: 0.9103 - val_loss: 0.3535 - val_categorical_accuracy: 0.9110\n",
      "Epoch 41/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2845 - categorical_accuracy: 0.9107 - val_loss: 0.3652 - val_categorical_accuracy: 0.9112\n",
      "Epoch 42/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2829 - categorical_accuracy: 0.9112 - val_loss: 0.3896 - val_categorical_accuracy: 0.9107\n",
      "Epoch 43/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2803 - categorical_accuracy: 0.9110 - val_loss: 0.3428 - val_categorical_accuracy: 0.9110\n",
      "Epoch 44/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2894 - categorical_accuracy: 0.9113 - val_loss: 0.3848 - val_categorical_accuracy: 0.9105\n",
      "Epoch 45/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2799 - categorical_accuracy: 0.9115 - val_loss: 0.3751 - val_categorical_accuracy: 0.9112\n",
      "Epoch 46/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2789 - categorical_accuracy: 0.9110 - val_loss: 0.3851 - val_categorical_accuracy: 0.9097\n",
      "Epoch 47/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2812 - categorical_accuracy: 0.9111 - val_loss: 0.3255 - val_categorical_accuracy: 0.9110\n",
      "Epoch 48/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2769 - categorical_accuracy: 0.9110 - val_loss: 0.4103 - val_categorical_accuracy: 0.9107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2728 - categorical_accuracy: 0.9106 - val_loss: 0.4706 - val_categorical_accuracy: 0.9105\n",
      "Epoch 50/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2795 - categorical_accuracy: 0.9111 - val_loss: 0.4215 - val_categorical_accuracy: 0.9105\n",
      "Epoch 51/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2779 - categorical_accuracy: 0.9104 - val_loss: 0.3433 - val_categorical_accuracy: 0.9107\n",
      "Epoch 52/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2750 - categorical_accuracy: 0.9111 - val_loss: 0.3881 - val_categorical_accuracy: 0.9115\n",
      "Epoch 53/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2742 - categorical_accuracy: 0.9105 - val_loss: 0.3949 - val_categorical_accuracy: 0.9112\n",
      "Epoch 54/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2773 - categorical_accuracy: 0.9113 - val_loss: 0.3984 - val_categorical_accuracy: 0.9122\n",
      "Epoch 55/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2713 - categorical_accuracy: 0.9102 - val_loss: 0.3653 - val_categorical_accuracy: 0.9112\n",
      "Epoch 56/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2769 - categorical_accuracy: 0.9104 - val_loss: 0.3876 - val_categorical_accuracy: 0.9122\n",
      "Epoch 57/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2709 - categorical_accuracy: 0.9104 - val_loss: 0.3630 - val_categorical_accuracy: 0.9105\n",
      "Epoch 58/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2692 - categorical_accuracy: 0.9110 - val_loss: 0.4114 - val_categorical_accuracy: 0.9120\n",
      "Epoch 59/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2693 - categorical_accuracy: 0.9103 - val_loss: 0.3291 - val_categorical_accuracy: 0.9122\n",
      "Epoch 60/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2772 - categorical_accuracy: 0.9105 - val_loss: 0.3426 - val_categorical_accuracy: 0.9120\n",
      "Epoch 61/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2744 - categorical_accuracy: 0.9107 - val_loss: 0.3687 - val_categorical_accuracy: 0.9110\n",
      "Epoch 62/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2687 - categorical_accuracy: 0.9110 - val_loss: 0.4804 - val_categorical_accuracy: 0.9110\n",
      "Epoch 63/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2666 - categorical_accuracy: 0.9111 - val_loss: 0.3655 - val_categorical_accuracy: 0.9115\n",
      "Epoch 64/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2672 - categorical_accuracy: 0.9105 - val_loss: 0.3662 - val_categorical_accuracy: 0.9118\n",
      "Epoch 65/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2704 - categorical_accuracy: 0.9109 - val_loss: 0.4644 - val_categorical_accuracy: 0.9112\n",
      "Epoch 66/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2705 - categorical_accuracy: 0.9106 - val_loss: 0.3551 - val_categorical_accuracy: 0.9125\n",
      "Epoch 67/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2663 - categorical_accuracy: 0.9103 - val_loss: 0.3970 - val_categorical_accuracy: 0.9110\n",
      "Epoch 68/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2686 - categorical_accuracy: 0.9110 - val_loss: 0.4453 - val_categorical_accuracy: 0.9115\n",
      "Epoch 69/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2672 - categorical_accuracy: 0.9125 - val_loss: 0.3162 - val_categorical_accuracy: 0.9128\n",
      "Epoch 70/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2764 - categorical_accuracy: 0.9119 - val_loss: 0.3355 - val_categorical_accuracy: 0.9120\n",
      "Epoch 71/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2750 - categorical_accuracy: 0.9136 - val_loss: 0.3577 - val_categorical_accuracy: 0.9128\n",
      "Epoch 72/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2648 - categorical_accuracy: 0.9133 - val_loss: 0.3803 - val_categorical_accuracy: 0.9120\n",
      "Epoch 73/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2662 - categorical_accuracy: 0.9133 - val_loss: 0.4050 - val_categorical_accuracy: 0.9118\n",
      "Epoch 74/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2656 - categorical_accuracy: 0.9135 - val_loss: 0.3891 - val_categorical_accuracy: 0.9120\n",
      "Epoch 75/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2703 - categorical_accuracy: 0.9148 - val_loss: 0.3799 - val_categorical_accuracy: 0.9128\n",
      "Epoch 76/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2623 - categorical_accuracy: 0.9140 - val_loss: 0.3326 - val_categorical_accuracy: 0.9128\n",
      "Epoch 77/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2636 - categorical_accuracy: 0.9124 - val_loss: 0.3809 - val_categorical_accuracy: 0.9125\n",
      "Epoch 78/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2662 - categorical_accuracy: 0.9132 - val_loss: 0.3739 - val_categorical_accuracy: 0.9128\n",
      "Epoch 79/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2626 - categorical_accuracy: 0.9133 - val_loss: 0.3819 - val_categorical_accuracy: 0.9133\n",
      "Epoch 80/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2615 - categorical_accuracy: 0.9132 - val_loss: 0.5744 - val_categorical_accuracy: 0.8030\n",
      "Epoch 81/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2669 - categorical_accuracy: 0.9122 - val_loss: 0.3420 - val_categorical_accuracy: 0.9133\n",
      "Epoch 82/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2621 - categorical_accuracy: 0.9145 - val_loss: 0.4357 - val_categorical_accuracy: 0.9135\n",
      "Epoch 83/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2642 - categorical_accuracy: 0.9143 - val_loss: 0.4201 - val_categorical_accuracy: 0.9128\n",
      "Epoch 84/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2622 - categorical_accuracy: 0.9139 - val_loss: 0.3542 - val_categorical_accuracy: 0.9128\n",
      "Epoch 85/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2622 - categorical_accuracy: 0.9140 - val_loss: 0.4334 - val_categorical_accuracy: 0.9128\n",
      "Epoch 86/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2617 - categorical_accuracy: 0.9144 - val_loss: 0.4232 - val_categorical_accuracy: 0.9128\n",
      "Epoch 87/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2617 - categorical_accuracy: 0.9131 - val_loss: 0.3675 - val_categorical_accuracy: 0.9128\n",
      "Epoch 88/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2610 - categorical_accuracy: 0.9135 - val_loss: 0.3493 - val_categorical_accuracy: 0.9137\n",
      "Epoch 89/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2617 - categorical_accuracy: 0.9124 - val_loss: 0.3872 - val_categorical_accuracy: 0.9128\n",
      "Epoch 90/200\n",
      "1040/1040 [==============================] - 6s 5ms/step - loss: 0.2659 - categorical_accuracy: 0.9124 - val_loss: 0.3570 - val_categorical_accuracy: 0.9128\n",
      "Epoch 91/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2587 - categorical_accuracy: 0.9149 - val_loss: 0.3375 - val_categorical_accuracy: 0.9137\n",
      "Epoch 92/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2584 - categorical_accuracy: 0.9135 - val_loss: 0.3734 - val_categorical_accuracy: 0.9140\n",
      "Epoch 93/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2591 - categorical_accuracy: 0.9128 - val_loss: 0.3925 - val_categorical_accuracy: 0.9135\n",
      "Epoch 94/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2574 - categorical_accuracy: 0.9140 - val_loss: 0.4123 - val_categorical_accuracy: 0.9143\n",
      "Epoch 95/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2583 - categorical_accuracy: 0.9121 - val_loss: 0.4179 - val_categorical_accuracy: 0.9137\n",
      "Epoch 96/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2568 - categorical_accuracy: 0.9127 - val_loss: 0.4505 - val_categorical_accuracy: 0.9140\n",
      "Epoch 97/200\n",
      "1040/1040 [==============================] - 6s 6ms/step - loss: 0.2546 - categorical_accuracy: 0.9121 - val_loss: 0.3667 - val_categorical_accuracy: 0.9140\n",
      "Epoch 98/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2597 - categorical_accuracy: 0.9118 - val_loss: 0.4306 - val_categorical_accuracy: 0.9130\n",
      "Epoch 99/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2538 - categorical_accuracy: 0.9117 - val_loss: 0.4118 - val_categorical_accuracy: 0.9137\n",
      "Epoch 100/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2513 - categorical_accuracy: 0.9114 - val_loss: 0.3586 - val_categorical_accuracy: 0.9145\n",
      "Epoch 101/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2516 - categorical_accuracy: 0.9115 - val_loss: 0.3610 - val_categorical_accuracy: 0.9145\n",
      "Epoch 102/200\n",
      "1040/1040 [==============================] - 6s 5ms/step - loss: 0.2506 - categorical_accuracy: 0.9113 - val_loss: 0.4875 - val_categorical_accuracy: 0.9153\n",
      "Epoch 103/200\n",
      "1040/1040 [==============================] - 6s 6ms/step - loss: 0.2571 - categorical_accuracy: 0.9101 - val_loss: 0.4124 - val_categorical_accuracy: 0.9140\n",
      "Epoch 104/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2490 - categorical_accuracy: 0.9116 - val_loss: 0.3629 - val_categorical_accuracy: 0.9128\n",
      "Epoch 105/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2499 - categorical_accuracy: 0.9129 - val_loss: 0.5038 - val_categorical_accuracy: 0.8662\n",
      "Epoch 106/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2567 - categorical_accuracy: 0.9119 - val_loss: 0.3571 - val_categorical_accuracy: 0.9143\n",
      "Epoch 107/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2482 - categorical_accuracy: 0.9113 - val_loss: 0.4003 - val_categorical_accuracy: 0.9133\n",
      "Epoch 108/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2500 - categorical_accuracy: 0.9103 - val_loss: 0.3803 - val_categorical_accuracy: 0.9147\n",
      "Epoch 109/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2498 - categorical_accuracy: 0.9119 - val_loss: 0.3314 - val_categorical_accuracy: 0.9137\n",
      "Epoch 110/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2520 - categorical_accuracy: 0.9108 - val_loss: 0.4104 - val_categorical_accuracy: 0.9133\n",
      "Epoch 111/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2492 - categorical_accuracy: 0.9131 - val_loss: 0.3779 - val_categorical_accuracy: 0.9137\n",
      "Epoch 112/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2494 - categorical_accuracy: 0.9124 - val_loss: 0.3732 - val_categorical_accuracy: 0.9125\n",
      "Epoch 113/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2488 - categorical_accuracy: 0.9127 - val_loss: 0.3834 - val_categorical_accuracy: 0.9155\n",
      "Epoch 114/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2463 - categorical_accuracy: 0.9123 - val_loss: 0.3326 - val_categorical_accuracy: 0.9143\n",
      "Epoch 115/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2482 - categorical_accuracy: 0.9123 - val_loss: 0.3498 - val_categorical_accuracy: 0.9140\n",
      "Epoch 116/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2456 - categorical_accuracy: 0.9131 - val_loss: 0.4011 - val_categorical_accuracy: 0.9150\n",
      "Epoch 117/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2473 - categorical_accuracy: 0.9129 - val_loss: 0.4114 - val_categorical_accuracy: 0.9150\n",
      "Epoch 118/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2464 - categorical_accuracy: 0.9144 - val_loss: 0.3754 - val_categorical_accuracy: 0.9145\n",
      "Epoch 119/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2464 - categorical_accuracy: 0.9125 - val_loss: 0.5368 - val_categorical_accuracy: 0.8480\n",
      "Epoch 120/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2467 - categorical_accuracy: 0.9138 - val_loss: 0.4079 - val_categorical_accuracy: 0.9145\n",
      "Epoch 121/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2458 - categorical_accuracy: 0.9138 - val_loss: 0.3595 - val_categorical_accuracy: 0.9145\n",
      "Epoch 122/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2440 - categorical_accuracy: 0.9148 - val_loss: 0.3624 - val_categorical_accuracy: 0.9147\n",
      "Epoch 123/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2461 - categorical_accuracy: 0.9139 - val_loss: 0.3972 - val_categorical_accuracy: 0.9160\n",
      "Epoch 124/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2477 - categorical_accuracy: 0.9135 - val_loss: 0.4000 - val_categorical_accuracy: 0.9165\n",
      "Epoch 125/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2438 - categorical_accuracy: 0.9140 - val_loss: 0.3653 - val_categorical_accuracy: 0.9150\n",
      "Epoch 126/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2454 - categorical_accuracy: 0.9137 - val_loss: 0.4127 - val_categorical_accuracy: 0.9150\n",
      "Epoch 127/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2441 - categorical_accuracy: 0.9156 - val_loss: 0.3512 - val_categorical_accuracy: 0.9160\n",
      "Epoch 128/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2420 - categorical_accuracy: 0.9148 - val_loss: 0.3704 - val_categorical_accuracy: 0.9160\n",
      "Epoch 129/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2430 - categorical_accuracy: 0.9154 - val_loss: 0.3825 - val_categorical_accuracy: 0.9162\n",
      "Epoch 130/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2429 - categorical_accuracy: 0.9150 - val_loss: 0.3290 - val_categorical_accuracy: 0.9160\n",
      "Epoch 131/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2447 - categorical_accuracy: 0.9146 - val_loss: 0.4033 - val_categorical_accuracy: 0.9162\n",
      "Epoch 132/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2426 - categorical_accuracy: 0.9156 - val_loss: 0.3775 - val_categorical_accuracy: 0.9165\n",
      "Epoch 133/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2434 - categorical_accuracy: 0.9143 - val_loss: 0.3629 - val_categorical_accuracy: 0.9172\n",
      "Epoch 134/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2445 - categorical_accuracy: 0.9152 - val_loss: 0.3874 - val_categorical_accuracy: 0.9162\n",
      "Epoch 135/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2410 - categorical_accuracy: 0.9170 - val_loss: 0.3741 - val_categorical_accuracy: 0.9165\n",
      "Epoch 136/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2477 - categorical_accuracy: 0.9159 - val_loss: 0.3542 - val_categorical_accuracy: 0.9158\n",
      "Epoch 137/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2422 - categorical_accuracy: 0.9164 - val_loss: 0.3898 - val_categorical_accuracy: 0.9165\n",
      "Epoch 138/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2424 - categorical_accuracy: 0.9169 - val_loss: 0.4287 - val_categorical_accuracy: 0.9170\n",
      "Epoch 139/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2403 - categorical_accuracy: 0.9182 - val_loss: 0.3483 - val_categorical_accuracy: 0.9162\n",
      "Epoch 140/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2407 - categorical_accuracy: 0.9152 - val_loss: 0.3350 - val_categorical_accuracy: 0.9168\n",
      "Epoch 141/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2436 - categorical_accuracy: 0.9159 - val_loss: 0.3743 - val_categorical_accuracy: 0.9168\n",
      "Epoch 142/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2391 - categorical_accuracy: 0.9164 - val_loss: 0.3224 - val_categorical_accuracy: 0.9172\n",
      "Epoch 143/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2446 - categorical_accuracy: 0.9157 - val_loss: 0.3955 - val_categorical_accuracy: 0.9178\n",
      "Epoch 144/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2399 - categorical_accuracy: 0.9175 - val_loss: 0.3415 - val_categorical_accuracy: 0.9187\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2392 - categorical_accuracy: 0.9159 - val_loss: 0.4151 - val_categorical_accuracy: 0.9183\n",
      "Epoch 146/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2400 - categorical_accuracy: 0.9169 - val_loss: 0.3330 - val_categorical_accuracy: 0.9180\n",
      "Epoch 147/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2427 - categorical_accuracy: 0.9159 - val_loss: 0.3807 - val_categorical_accuracy: 0.9178\n",
      "Epoch 148/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2385 - categorical_accuracy: 0.9192 - val_loss: 0.3448 - val_categorical_accuracy: 0.9185\n",
      "Epoch 149/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2437 - categorical_accuracy: 0.9184 - val_loss: 0.3852 - val_categorical_accuracy: 0.9165\n",
      "Epoch 150/200\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.2377 - categorical_accuracy: 0.9204 - val_loss: 0.3817 - val_categorical_accuracy: 0.9170\n",
      "Epoch 151/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2386 - categorical_accuracy: 0.9212 - val_loss: 0.3620 - val_categorical_accuracy: 0.9162\n",
      "Epoch 152/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2391 - categorical_accuracy: 0.9211 - val_loss: 0.3752 - val_categorical_accuracy: 0.9165\n",
      "Epoch 153/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2352 - categorical_accuracy: 0.9213 - val_loss: 0.3680 - val_categorical_accuracy: 0.9147\n",
      "Epoch 154/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2400 - categorical_accuracy: 0.9211 - val_loss: 0.4452 - val_categorical_accuracy: 0.9160\n",
      "Epoch 155/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2403 - categorical_accuracy: 0.9230 - val_loss: 0.4113 - val_categorical_accuracy: 0.9158\n",
      "Epoch 156/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2369 - categorical_accuracy: 0.9227 - val_loss: 0.4433 - val_categorical_accuracy: 0.9110\n",
      "Epoch 157/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2384 - categorical_accuracy: 0.9228 - val_loss: 0.4392 - val_categorical_accuracy: 0.9158\n",
      "Epoch 158/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2364 - categorical_accuracy: 0.9230 - val_loss: 0.3791 - val_categorical_accuracy: 0.9158\n",
      "Epoch 159/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2364 - categorical_accuracy: 0.9238 - val_loss: 0.3823 - val_categorical_accuracy: 0.9147\n",
      "Epoch 160/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2365 - categorical_accuracy: 0.9239 - val_loss: 0.3642 - val_categorical_accuracy: 0.9160\n",
      "Epoch 161/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2376 - categorical_accuracy: 0.9231 - val_loss: 0.4274 - val_categorical_accuracy: 0.9155\n",
      "Epoch 162/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2374 - categorical_accuracy: 0.9233 - val_loss: 0.3752 - val_categorical_accuracy: 0.9143\n",
      "Epoch 163/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2352 - categorical_accuracy: 0.9239 - val_loss: 0.3583 - val_categorical_accuracy: 0.9150\n",
      "Epoch 164/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2378 - categorical_accuracy: 0.9234 - val_loss: 0.3508 - val_categorical_accuracy: 0.9153\n",
      "Epoch 165/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2349 - categorical_accuracy: 0.9232 - val_loss: 0.4745 - val_categorical_accuracy: 0.8935\n",
      "Epoch 166/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2356 - categorical_accuracy: 0.9234 - val_loss: 0.4326 - val_categorical_accuracy: 0.9090\n",
      "Epoch 167/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2347 - categorical_accuracy: 0.9243 - val_loss: 0.3643 - val_categorical_accuracy: 0.9158\n",
      "Epoch 168/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2355 - categorical_accuracy: 0.9237 - val_loss: 0.3631 - val_categorical_accuracy: 0.9155\n",
      "Epoch 169/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2348 - categorical_accuracy: 0.9233 - val_loss: 0.4103 - val_categorical_accuracy: 0.9150\n",
      "Epoch 170/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2348 - categorical_accuracy: 0.9244 - val_loss: 0.3903 - val_categorical_accuracy: 0.9153\n",
      "Epoch 171/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2329 - categorical_accuracy: 0.9239 - val_loss: 0.4050 - val_categorical_accuracy: 0.9147\n",
      "Epoch 172/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2367 - categorical_accuracy: 0.9236 - val_loss: 0.3707 - val_categorical_accuracy: 0.9155\n",
      "Epoch 173/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2348 - categorical_accuracy: 0.9251 - val_loss: 0.4132 - val_categorical_accuracy: 0.9155\n",
      "Epoch 174/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2366 - categorical_accuracy: 0.9195 - val_loss: 0.3387 - val_categorical_accuracy: 0.9183\n",
      "Epoch 175/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2432 - categorical_accuracy: 0.9207 - val_loss: 0.3607 - val_categorical_accuracy: 0.9170\n",
      "Epoch 176/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2375 - categorical_accuracy: 0.9231 - val_loss: 0.4105 - val_categorical_accuracy: 0.9045\n",
      "Epoch 177/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2351 - categorical_accuracy: 0.9229 - val_loss: 0.4042 - val_categorical_accuracy: 0.9158\n",
      "Epoch 178/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2334 - categorical_accuracy: 0.9230 - val_loss: 0.3712 - val_categorical_accuracy: 0.9153\n",
      "Epoch 179/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2379 - categorical_accuracy: 0.9224 - val_loss: 0.4019 - val_categorical_accuracy: 0.9170\n",
      "Epoch 180/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2333 - categorical_accuracy: 0.9263 - val_loss: 0.3837 - val_categorical_accuracy: 0.9165\n",
      "Epoch 181/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2353 - categorical_accuracy: 0.9241 - val_loss: 0.4312 - val_categorical_accuracy: 0.9153\n",
      "Epoch 182/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2342 - categorical_accuracy: 0.9242 - val_loss: 0.4005 - val_categorical_accuracy: 0.9093\n",
      "Epoch 183/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2357 - categorical_accuracy: 0.9209 - val_loss: 0.3428 - val_categorical_accuracy: 0.9153\n",
      "Epoch 184/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2379 - categorical_accuracy: 0.9221 - val_loss: 0.4131 - val_categorical_accuracy: 0.9162\n",
      "Epoch 185/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2331 - categorical_accuracy: 0.9247 - val_loss: 0.3913 - val_categorical_accuracy: 0.9168\n",
      "Epoch 186/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2321 - categorical_accuracy: 0.9237 - val_loss: 0.3789 - val_categorical_accuracy: 0.9185\n",
      "Epoch 187/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2309 - categorical_accuracy: 0.9243 - val_loss: 0.3760 - val_categorical_accuracy: 0.9178\n",
      "Epoch 188/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2350 - categorical_accuracy: 0.9240 - val_loss: 0.4072 - val_categorical_accuracy: 0.9165\n",
      "Epoch 189/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2331 - categorical_accuracy: 0.9237 - val_loss: 0.3990 - val_categorical_accuracy: 0.9168\n",
      "Epoch 190/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2301 - categorical_accuracy: 0.9238 - val_loss: 0.3594 - val_categorical_accuracy: 0.9160\n",
      "Epoch 191/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2334 - categorical_accuracy: 0.9234 - val_loss: 0.3702 - val_categorical_accuracy: 0.9153\n",
      "Epoch 192/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2323 - categorical_accuracy: 0.9231 - val_loss: 0.4099 - val_categorical_accuracy: 0.9168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2326 - categorical_accuracy: 0.9244 - val_loss: 0.3792 - val_categorical_accuracy: 0.9165\n",
      "Epoch 194/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2301 - categorical_accuracy: 0.9247 - val_loss: 0.3871 - val_categorical_accuracy: 0.9180\n",
      "Epoch 195/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2339 - categorical_accuracy: 0.9236 - val_loss: 0.3722 - val_categorical_accuracy: 0.9165\n",
      "Epoch 196/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2288 - categorical_accuracy: 0.9247 - val_loss: 0.3822 - val_categorical_accuracy: 0.9170\n",
      "Epoch 197/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2342 - categorical_accuracy: 0.9247 - val_loss: 0.3479 - val_categorical_accuracy: 0.9178\n",
      "Epoch 198/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2331 - categorical_accuracy: 0.9250 - val_loss: 0.3446 - val_categorical_accuracy: 0.9168\n",
      "Epoch 199/200\n",
      "1040/1040 [==============================] - 5s 5ms/step - loss: 0.2372 - categorical_accuracy: 0.9223 - val_loss: 0.3443 - val_categorical_accuracy: 0.9168\n",
      "Epoch 200/200\n",
      "1040/1040 [==============================] - 5s 4ms/step - loss: 0.2325 - categorical_accuracy: 0.9236 - val_loss: 0.4179 - val_categorical_accuracy: 0.9100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( \n",
    "    np.array([x_train_set[i:i+200] for i in range(0,104000,100)]),\n",
    "    np.array([target_onehot[i:i+200] for i in range(0,104000,100)]),\n",
    "    epochs=200,\n",
    "    validation_data = (np.array([x_train_set[i:i+200] for i in range(104000,105000,50)]),\n",
    "                     np.array([target_onehot[i:i+200] for i in range(104000,105000,50)])),\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2780 samples, validate on 20 samples\n",
      "Epoch 1/200\n",
      "2780/2780 [==============================] - 9s 3ms/step - loss: 0.7284 - categorical_accuracy: 0.8811 - val_loss: 0.5829 - val_categorical_accuracy: 0.7990\n",
      "Epoch 2/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.4361 - categorical_accuracy: 0.8974 - val_loss: 0.6139 - val_categorical_accuracy: 0.7990\n",
      "Epoch 3/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.4186 - categorical_accuracy: 0.8974 - val_loss: 0.6130 - val_categorical_accuracy: 0.7990\n",
      "Epoch 4/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.4086 - categorical_accuracy: 0.8974 - val_loss: 0.6049 - val_categorical_accuracy: 0.7990\n",
      "Epoch 5/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.3991 - categorical_accuracy: 0.8974 - val_loss: 0.5988 - val_categorical_accuracy: 0.7990\n",
      "Epoch 6/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.3861 - categorical_accuracy: 0.8974 - val_loss: 0.5527 - val_categorical_accuracy: 0.7990\n",
      "Epoch 7/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.3738 - categorical_accuracy: 0.8978 - val_loss: 0.5427 - val_categorical_accuracy: 0.8275\n",
      "Epoch 8/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.3636 - categorical_accuracy: 0.8999 - val_loss: 0.5389 - val_categorical_accuracy: 0.8075\n",
      "Epoch 9/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.3533 - categorical_accuracy: 0.9009 - val_loss: 0.5138 - val_categorical_accuracy: 0.8445\n",
      "Epoch 10/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.3421 - categorical_accuracy: 0.9030 - val_loss: 0.5319 - val_categorical_accuracy: 0.8455\n",
      "Epoch 11/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.3310 - categorical_accuracy: 0.9029 - val_loss: 0.5495 - val_categorical_accuracy: 0.8480\n",
      "Epoch 12/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.3221 - categorical_accuracy: 0.9026 - val_loss: 0.5547 - val_categorical_accuracy: 0.8575\n",
      "Epoch 13/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.3149 - categorical_accuracy: 0.9028 - val_loss: 0.5449 - val_categorical_accuracy: 0.8580\n",
      "Epoch 14/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.3085 - categorical_accuracy: 0.9030 - val_loss: 0.5876 - val_categorical_accuracy: 0.8510\n",
      "Epoch 15/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.3043 - categorical_accuracy: 0.9032 - val_loss: 0.5758 - val_categorical_accuracy: 0.8575\n",
      "Epoch 16/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.3009 - categorical_accuracy: 0.9030 - val_loss: 0.6047 - val_categorical_accuracy: 0.8475\n",
      "Epoch 17/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2989 - categorical_accuracy: 0.9033 - val_loss: 0.5849 - val_categorical_accuracy: 0.8555\n",
      "Epoch 18/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2971 - categorical_accuracy: 0.9030 - val_loss: 0.6089 - val_categorical_accuracy: 0.8520\n",
      "Epoch 19/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2976 - categorical_accuracy: 0.9034 - val_loss: 0.5446 - val_categorical_accuracy: 0.8625\n",
      "Epoch 20/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2947 - categorical_accuracy: 0.9031 - val_loss: 0.5289 - val_categorical_accuracy: 0.8625\n",
      "Epoch 21/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2946 - categorical_accuracy: 0.9034 - val_loss: 0.6177 - val_categorical_accuracy: 0.8565\n",
      "Epoch 22/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2929 - categorical_accuracy: 0.9040 - val_loss: 0.5824 - val_categorical_accuracy: 0.8635\n",
      "Epoch 23/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2915 - categorical_accuracy: 0.9037 - val_loss: 0.5503 - val_categorical_accuracy: 0.8615\n",
      "Epoch 24/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2912 - categorical_accuracy: 0.9039 - val_loss: 0.6602 - val_categorical_accuracy: 0.8530\n",
      "Epoch 25/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2914 - categorical_accuracy: 0.9041 - val_loss: 0.6258 - val_categorical_accuracy: 0.8630\n",
      "Epoch 26/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2898 - categorical_accuracy: 0.9037 - val_loss: 0.6730 - val_categorical_accuracy: 0.8580\n",
      "Epoch 27/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2907 - categorical_accuracy: 0.9037 - val_loss: 0.6005 - val_categorical_accuracy: 0.8625\n",
      "Epoch 28/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2896 - categorical_accuracy: 0.9041 - val_loss: 0.5702 - val_categorical_accuracy: 0.8570\n",
      "Epoch 29/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2896 - categorical_accuracy: 0.9040 - val_loss: 0.5890 - val_categorical_accuracy: 0.8600\n",
      "Epoch 30/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2889 - categorical_accuracy: 0.9041 - val_loss: 0.5731 - val_categorical_accuracy: 0.8625\n",
      "Epoch 31/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2885 - categorical_accuracy: 0.9056 - val_loss: 0.6033 - val_categorical_accuracy: 0.8615\n",
      "Epoch 32/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2875 - categorical_accuracy: 0.9062 - val_loss: 0.5609 - val_categorical_accuracy: 0.8635\n",
      "Epoch 33/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2877 - categorical_accuracy: 0.9045 - val_loss: 0.6004 - val_categorical_accuracy: 0.8590\n",
      "Epoch 34/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2879 - categorical_accuracy: 0.9058 - val_loss: 0.5677 - val_categorical_accuracy: 0.8580\n",
      "Epoch 35/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2868 - categorical_accuracy: 0.9052 - val_loss: 0.6296 - val_categorical_accuracy: 0.8600\n",
      "Epoch 36/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2873 - categorical_accuracy: 0.9064 - val_loss: 0.5562 - val_categorical_accuracy: 0.8635\n",
      "Epoch 37/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2865 - categorical_accuracy: 0.9058 - val_loss: 0.5688 - val_categorical_accuracy: 0.8610\n",
      "Epoch 38/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2860 - categorical_accuracy: 0.9063 - val_loss: 0.5649 - val_categorical_accuracy: 0.8630\n",
      "Epoch 39/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2857 - categorical_accuracy: 0.9057 - val_loss: 0.5951 - val_categorical_accuracy: 0.8615\n",
      "Epoch 40/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2859 - categorical_accuracy: 0.9059 - val_loss: 0.5370 - val_categorical_accuracy: 0.8590\n",
      "Epoch 41/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2840 - categorical_accuracy: 0.9063 - val_loss: 0.5225 - val_categorical_accuracy: 0.8635\n",
      "Epoch 42/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2840 - categorical_accuracy: 0.9063 - val_loss: 0.5501 - val_categorical_accuracy: 0.8615\n",
      "Epoch 43/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2834 - categorical_accuracy: 0.9056 - val_loss: 0.5768 - val_categorical_accuracy: 0.8680\n",
      "Epoch 44/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2826 - categorical_accuracy: 0.9046 - val_loss: 0.5593 - val_categorical_accuracy: 0.8600\n",
      "Epoch 45/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2817 - categorical_accuracy: 0.9048 - val_loss: 0.6200 - val_categorical_accuracy: 0.8630\n",
      "Epoch 46/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2798 - categorical_accuracy: 0.9057 - val_loss: 0.6534 - val_categorical_accuracy: 0.8370\n",
      "Epoch 47/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2813 - categorical_accuracy: 0.9051 - val_loss: 0.6443 - val_categorical_accuracy: 0.8390\n",
      "Epoch 48/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2802 - categorical_accuracy: 0.9056 - val_loss: 0.5943 - val_categorical_accuracy: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2781 - categorical_accuracy: 0.9048 - val_loss: 0.5469 - val_categorical_accuracy: 0.8610\n",
      "Epoch 50/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2798 - categorical_accuracy: 0.9046 - val_loss: 0.5926 - val_categorical_accuracy: 0.8585\n",
      "Epoch 51/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2789 - categorical_accuracy: 0.9049 - val_loss: 0.5744 - val_categorical_accuracy: 0.8615\n",
      "Epoch 52/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2779 - categorical_accuracy: 0.9050 - val_loss: 0.5905 - val_categorical_accuracy: 0.8575\n",
      "Epoch 53/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2776 - categorical_accuracy: 0.9055 - val_loss: 0.5880 - val_categorical_accuracy: 0.8585\n",
      "Epoch 54/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2795 - categorical_accuracy: 0.9060 - val_loss: 0.6026 - val_categorical_accuracy: 0.8605\n",
      "Epoch 55/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2789 - categorical_accuracy: 0.9053 - val_loss: 0.5535 - val_categorical_accuracy: 0.8560\n",
      "Epoch 56/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2775 - categorical_accuracy: 0.9062 - val_loss: 0.6311 - val_categorical_accuracy: 0.8460\n",
      "Epoch 57/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2787 - categorical_accuracy: 0.9047 - val_loss: 0.5700 - val_categorical_accuracy: 0.8690\n",
      "Epoch 58/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2764 - categorical_accuracy: 0.9044 - val_loss: 0.5969 - val_categorical_accuracy: 0.8665\n",
      "Epoch 59/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2776 - categorical_accuracy: 0.9045 - val_loss: 0.5724 - val_categorical_accuracy: 0.8630\n",
      "Epoch 60/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2779 - categorical_accuracy: 0.9049 - val_loss: 0.6002 - val_categorical_accuracy: 0.8610\n",
      "Epoch 61/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2772 - categorical_accuracy: 0.9043 - val_loss: 0.5732 - val_categorical_accuracy: 0.8615\n",
      "Epoch 62/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2767 - categorical_accuracy: 0.9069 - val_loss: 0.5407 - val_categorical_accuracy: 0.8590\n",
      "Epoch 63/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2766 - categorical_accuracy: 0.9057 - val_loss: 0.6584 - val_categorical_accuracy: 0.8280\n",
      "Epoch 64/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2772 - categorical_accuracy: 0.9061 - val_loss: 0.5885 - val_categorical_accuracy: 0.8655\n",
      "Epoch 65/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2762 - categorical_accuracy: 0.9061 - val_loss: 0.6129 - val_categorical_accuracy: 0.8635\n",
      "Epoch 66/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2765 - categorical_accuracy: 0.9069 - val_loss: 0.5851 - val_categorical_accuracy: 0.8595\n",
      "Epoch 67/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2747 - categorical_accuracy: 0.9067 - val_loss: 0.5459 - val_categorical_accuracy: 0.8630\n",
      "Epoch 68/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2766 - categorical_accuracy: 0.9069 - val_loss: 0.5381 - val_categorical_accuracy: 0.8670\n",
      "Epoch 69/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2759 - categorical_accuracy: 0.9069 - val_loss: 0.5791 - val_categorical_accuracy: 0.8670\n",
      "Epoch 70/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2765 - categorical_accuracy: 0.9070 - val_loss: 0.5819 - val_categorical_accuracy: 0.8620\n",
      "Epoch 71/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2749 - categorical_accuracy: 0.9078 - val_loss: 0.5805 - val_categorical_accuracy: 0.8655\n",
      "Epoch 72/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2760 - categorical_accuracy: 0.9070 - val_loss: 0.5782 - val_categorical_accuracy: 0.8670\n",
      "Epoch 73/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2742 - categorical_accuracy: 0.9066 - val_loss: 0.5676 - val_categorical_accuracy: 0.8670\n",
      "Epoch 74/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2748 - categorical_accuracy: 0.9074 - val_loss: 0.5550 - val_categorical_accuracy: 0.8675\n",
      "Epoch 75/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2753 - categorical_accuracy: 0.9057 - val_loss: 0.5576 - val_categorical_accuracy: 0.8690\n",
      "Epoch 76/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2748 - categorical_accuracy: 0.9059 - val_loss: 0.5721 - val_categorical_accuracy: 0.8670\n",
      "Epoch 77/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2755 - categorical_accuracy: 0.9065 - val_loss: 0.6045 - val_categorical_accuracy: 0.8580\n",
      "Epoch 78/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2738 - categorical_accuracy: 0.9066 - val_loss: 0.5622 - val_categorical_accuracy: 0.8685\n",
      "Epoch 79/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2746 - categorical_accuracy: 0.9061 - val_loss: 0.5471 - val_categorical_accuracy: 0.8680\n",
      "Epoch 80/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2748 - categorical_accuracy: 0.9080 - val_loss: 0.5814 - val_categorical_accuracy: 0.8675\n",
      "Epoch 81/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2728 - categorical_accuracy: 0.9087 - val_loss: 0.5667 - val_categorical_accuracy: 0.8680\n",
      "Epoch 82/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2733 - categorical_accuracy: 0.9068 - val_loss: 0.5336 - val_categorical_accuracy: 0.8675\n",
      "Epoch 83/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2747 - categorical_accuracy: 0.9067 - val_loss: 0.5714 - val_categorical_accuracy: 0.8635\n",
      "Epoch 84/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2742 - categorical_accuracy: 0.9068 - val_loss: 0.5889 - val_categorical_accuracy: 0.8690\n",
      "Epoch 85/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2729 - categorical_accuracy: 0.9071 - val_loss: 0.5412 - val_categorical_accuracy: 0.8690\n",
      "Epoch 86/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2738 - categorical_accuracy: 0.9073 - val_loss: 0.5683 - val_categorical_accuracy: 0.8705\n",
      "Epoch 87/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2726 - categorical_accuracy: 0.9071 - val_loss: 0.5458 - val_categorical_accuracy: 0.8705\n",
      "Epoch 88/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2721 - categorical_accuracy: 0.9061 - val_loss: 0.5127 - val_categorical_accuracy: 0.8690\n",
      "Epoch 89/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2725 - categorical_accuracy: 0.9063 - val_loss: 0.5868 - val_categorical_accuracy: 0.8600\n",
      "Epoch 90/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2723 - categorical_accuracy: 0.9042 - val_loss: 0.5949 - val_categorical_accuracy: 0.8655\n",
      "Epoch 91/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2728 - categorical_accuracy: 0.9037 - val_loss: 0.5562 - val_categorical_accuracy: 0.8720\n",
      "Epoch 92/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2715 - categorical_accuracy: 0.9055 - val_loss: 0.5660 - val_categorical_accuracy: 0.8640\n",
      "Epoch 93/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2711 - categorical_accuracy: 0.9047 - val_loss: 0.5137 - val_categorical_accuracy: 0.8730\n",
      "Epoch 94/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2725 - categorical_accuracy: 0.9060 - val_loss: 0.5724 - val_categorical_accuracy: 0.8665\n",
      "Epoch 95/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2722 - categorical_accuracy: 0.9052 - val_loss: 0.5585 - val_categorical_accuracy: 0.8660\n",
      "Epoch 96/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2716 - categorical_accuracy: 0.9038 - val_loss: 0.5930 - val_categorical_accuracy: 0.8630\n",
      "Epoch 97/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2720 - categorical_accuracy: 0.9049 - val_loss: 0.5486 - val_categorical_accuracy: 0.8630\n",
      "Epoch 98/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2703 - categorical_accuracy: 0.9046 - val_loss: 0.5631 - val_categorical_accuracy: 0.8620\n",
      "Epoch 99/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2725 - categorical_accuracy: 0.9052 - val_loss: 0.5519 - val_categorical_accuracy: 0.8640\n",
      "Epoch 100/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2715 - categorical_accuracy: 0.9060 - val_loss: 0.5418 - val_categorical_accuracy: 0.8650\n",
      "Epoch 101/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2695 - categorical_accuracy: 0.9061 - val_loss: 0.5731 - val_categorical_accuracy: 0.8625\n",
      "Epoch 102/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2713 - categorical_accuracy: 0.9058 - val_loss: 0.5808 - val_categorical_accuracy: 0.8655\n",
      "Epoch 103/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2705 - categorical_accuracy: 0.9047 - val_loss: 0.5344 - val_categorical_accuracy: 0.8660\n",
      "Epoch 104/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2708 - categorical_accuracy: 0.9056 - val_loss: 0.5584 - val_categorical_accuracy: 0.8655\n",
      "Epoch 105/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2707 - categorical_accuracy: 0.9061 - val_loss: 0.5287 - val_categorical_accuracy: 0.8690\n",
      "Epoch 106/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2710 - categorical_accuracy: 0.9071 - val_loss: 0.5503 - val_categorical_accuracy: 0.8650\n",
      "Epoch 107/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2699 - categorical_accuracy: 0.9066 - val_loss: 0.5163 - val_categorical_accuracy: 0.8675\n",
      "Epoch 108/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2687 - categorical_accuracy: 0.9072 - val_loss: 0.5565 - val_categorical_accuracy: 0.8630\n",
      "Epoch 109/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2702 - categorical_accuracy: 0.9066 - val_loss: 0.5558 - val_categorical_accuracy: 0.8690\n",
      "Epoch 110/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2709 - categorical_accuracy: 0.9062 - val_loss: 0.5276 - val_categorical_accuracy: 0.8705\n",
      "Epoch 111/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2688 - categorical_accuracy: 0.9064 - val_loss: 0.5824 - val_categorical_accuracy: 0.8645\n",
      "Epoch 112/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2690 - categorical_accuracy: 0.9049 - val_loss: 0.5021 - val_categorical_accuracy: 0.8645\n",
      "Epoch 113/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2703 - categorical_accuracy: 0.9058 - val_loss: 0.5195 - val_categorical_accuracy: 0.8660\n",
      "Epoch 114/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2703 - categorical_accuracy: 0.9072 - val_loss: 0.5574 - val_categorical_accuracy: 0.8655\n",
      "Epoch 115/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2695 - categorical_accuracy: 0.9086 - val_loss: 0.5420 - val_categorical_accuracy: 0.8640\n",
      "Epoch 116/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2690 - categorical_accuracy: 0.9081 - val_loss: 0.5133 - val_categorical_accuracy: 0.8690\n",
      "Epoch 117/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2688 - categorical_accuracy: 0.9088 - val_loss: 0.5585 - val_categorical_accuracy: 0.8695\n",
      "Epoch 118/200\n",
      "2780/2780 [==============================] - 5s 2ms/step - loss: 0.2697 - categorical_accuracy: 0.9091 - val_loss: 0.5706 - val_categorical_accuracy: 0.8650\n",
      "Epoch 119/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2693 - categorical_accuracy: 0.9086 - val_loss: 0.5276 - val_categorical_accuracy: 0.8665\n",
      "Epoch 120/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2681 - categorical_accuracy: 0.9096 - val_loss: 0.5539 - val_categorical_accuracy: 0.8685\n",
      "Epoch 121/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2677 - categorical_accuracy: 0.9088 - val_loss: 0.5193 - val_categorical_accuracy: 0.8695\n",
      "Epoch 122/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2691 - categorical_accuracy: 0.9078 - val_loss: 0.5103 - val_categorical_accuracy: 0.8710\n",
      "Epoch 123/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2678 - categorical_accuracy: 0.9087 - val_loss: 0.5116 - val_categorical_accuracy: 0.8690\n",
      "Epoch 124/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2672 - categorical_accuracy: 0.9087 - val_loss: 0.5529 - val_categorical_accuracy: 0.8710\n",
      "Epoch 125/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2678 - categorical_accuracy: 0.9087 - val_loss: 0.5192 - val_categorical_accuracy: 0.8710\n",
      "Epoch 126/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2690 - categorical_accuracy: 0.9090 - val_loss: 0.5364 - val_categorical_accuracy: 0.8695\n",
      "Epoch 127/200\n",
      "2780/2780 [==============================] - 7s 3ms/step - loss: 0.2675 - categorical_accuracy: 0.9092 - val_loss: 0.5601 - val_categorical_accuracy: 0.8400\n",
      "Epoch 128/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2689 - categorical_accuracy: 0.9088 - val_loss: 0.5065 - val_categorical_accuracy: 0.8710\n",
      "Epoch 129/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2673 - categorical_accuracy: 0.9101 - val_loss: 0.5160 - val_categorical_accuracy: 0.8735\n",
      "Epoch 130/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2670 - categorical_accuracy: 0.9097 - val_loss: 0.5057 - val_categorical_accuracy: 0.8740\n",
      "Epoch 131/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2674 - categorical_accuracy: 0.9096 - val_loss: 0.5314 - val_categorical_accuracy: 0.8710\n",
      "Epoch 132/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2666 - categorical_accuracy: 0.9087 - val_loss: 0.4762 - val_categorical_accuracy: 0.8725\n",
      "Epoch 133/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2674 - categorical_accuracy: 0.9102 - val_loss: 0.5210 - val_categorical_accuracy: 0.8715\n",
      "Epoch 134/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2675 - categorical_accuracy: 0.9090 - val_loss: 0.5182 - val_categorical_accuracy: 0.8720\n",
      "Epoch 135/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2682 - categorical_accuracy: 0.9102 - val_loss: 0.5158 - val_categorical_accuracy: 0.8745\n",
      "Epoch 136/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2664 - categorical_accuracy: 0.9098 - val_loss: 0.4881 - val_categorical_accuracy: 0.8720\n",
      "Epoch 137/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2686 - categorical_accuracy: 0.9077 - val_loss: 0.5462 - val_categorical_accuracy: 0.8695\n",
      "Epoch 138/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2671 - categorical_accuracy: 0.9097 - val_loss: 0.4965 - val_categorical_accuracy: 0.8735\n",
      "Epoch 139/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2674 - categorical_accuracy: 0.9096 - val_loss: 0.5302 - val_categorical_accuracy: 0.8670\n",
      "Epoch 140/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2664 - categorical_accuracy: 0.9098 - val_loss: 0.4879 - val_categorical_accuracy: 0.8690\n",
      "Epoch 141/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2682 - categorical_accuracy: 0.9091 - val_loss: 0.5267 - val_categorical_accuracy: 0.8680\n",
      "Epoch 142/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2676 - categorical_accuracy: 0.9095 - val_loss: 0.5254 - val_categorical_accuracy: 0.8740\n",
      "Epoch 143/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2655 - categorical_accuracy: 0.9102 - val_loss: 0.5237 - val_categorical_accuracy: 0.8770\n",
      "Epoch 144/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2683 - categorical_accuracy: 0.9096 - val_loss: 0.5146 - val_categorical_accuracy: 0.8725\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2668 - categorical_accuracy: 0.9102 - val_loss: 0.5124 - val_categorical_accuracy: 0.8755\n",
      "Epoch 146/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2663 - categorical_accuracy: 0.9103 - val_loss: 0.5038 - val_categorical_accuracy: 0.8755\n",
      "Epoch 147/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2666 - categorical_accuracy: 0.9106 - val_loss: 0.5117 - val_categorical_accuracy: 0.8760\n",
      "Epoch 148/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2676 - categorical_accuracy: 0.9084 - val_loss: 0.5120 - val_categorical_accuracy: 0.8740\n",
      "Epoch 149/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2666 - categorical_accuracy: 0.9099 - val_loss: 0.4999 - val_categorical_accuracy: 0.8765\n",
      "Epoch 150/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2664 - categorical_accuracy: 0.9092 - val_loss: 0.5231 - val_categorical_accuracy: 0.8785\n",
      "Epoch 151/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2671 - categorical_accuracy: 0.9092 - val_loss: 0.4885 - val_categorical_accuracy: 0.8785\n",
      "Epoch 152/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2663 - categorical_accuracy: 0.9092 - val_loss: 0.5069 - val_categorical_accuracy: 0.8755\n",
      "Epoch 153/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2646 - categorical_accuracy: 0.9104 - val_loss: 0.4912 - val_categorical_accuracy: 0.8785\n",
      "Epoch 154/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2656 - categorical_accuracy: 0.9096 - val_loss: 0.4961 - val_categorical_accuracy: 0.8765\n",
      "Epoch 155/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2645 - categorical_accuracy: 0.9102 - val_loss: 0.5118 - val_categorical_accuracy: 0.8765\n",
      "Epoch 156/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2668 - categorical_accuracy: 0.9099 - val_loss: 0.4978 - val_categorical_accuracy: 0.8785\n",
      "Epoch 157/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2662 - categorical_accuracy: 0.9113 - val_loss: 0.5116 - val_categorical_accuracy: 0.8785\n",
      "Epoch 158/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2666 - categorical_accuracy: 0.9112 - val_loss: 0.5029 - val_categorical_accuracy: 0.8785\n",
      "Epoch 159/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2651 - categorical_accuracy: 0.9115 - val_loss: 0.5222 - val_categorical_accuracy: 0.8785\n",
      "Epoch 160/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2651 - categorical_accuracy: 0.9099 - val_loss: 0.4874 - val_categorical_accuracy: 0.8765\n",
      "Epoch 161/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2653 - categorical_accuracy: 0.9111 - val_loss: 0.5124 - val_categorical_accuracy: 0.8780\n",
      "Epoch 162/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2654 - categorical_accuracy: 0.9090 - val_loss: 0.4844 - val_categorical_accuracy: 0.8785\n",
      "Epoch 163/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2650 - categorical_accuracy: 0.9109 - val_loss: 0.4907 - val_categorical_accuracy: 0.8770\n",
      "Epoch 164/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2652 - categorical_accuracy: 0.9112 - val_loss: 0.5211 - val_categorical_accuracy: 0.8775\n",
      "Epoch 165/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2658 - categorical_accuracy: 0.9114 - val_loss: 0.5223 - val_categorical_accuracy: 0.8770\n",
      "Epoch 166/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2631 - categorical_accuracy: 0.9113 - val_loss: 0.5041 - val_categorical_accuracy: 0.8770\n",
      "Epoch 167/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2640 - categorical_accuracy: 0.9118 - val_loss: 0.5241 - val_categorical_accuracy: 0.8780\n",
      "Epoch 168/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2667 - categorical_accuracy: 0.9111 - val_loss: 0.5324 - val_categorical_accuracy: 0.8750\n",
      "Epoch 169/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2635 - categorical_accuracy: 0.9121 - val_loss: 0.5340 - val_categorical_accuracy: 0.8785\n",
      "Epoch 170/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2627 - categorical_accuracy: 0.9117 - val_loss: 0.4880 - val_categorical_accuracy: 0.8800\n",
      "Epoch 171/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2638 - categorical_accuracy: 0.9121 - val_loss: 0.5075 - val_categorical_accuracy: 0.8805\n",
      "Epoch 172/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2633 - categorical_accuracy: 0.9134 - val_loss: 0.5220 - val_categorical_accuracy: 0.8785\n",
      "Epoch 173/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2653 - categorical_accuracy: 0.9106 - val_loss: 0.5044 - val_categorical_accuracy: 0.8800\n",
      "Epoch 174/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2632 - categorical_accuracy: 0.9118 - val_loss: 0.4927 - val_categorical_accuracy: 0.8675\n",
      "Epoch 175/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2642 - categorical_accuracy: 0.9114 - val_loss: 0.5441 - val_categorical_accuracy: 0.8665\n",
      "Epoch 176/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2640 - categorical_accuracy: 0.9129 - val_loss: 0.5023 - val_categorical_accuracy: 0.8650\n",
      "Epoch 177/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2623 - categorical_accuracy: 0.9135 - val_loss: 0.5261 - val_categorical_accuracy: 0.8650\n",
      "Epoch 178/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2647 - categorical_accuracy: 0.9111 - val_loss: 0.5220 - val_categorical_accuracy: 0.8650\n",
      "Epoch 179/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2644 - categorical_accuracy: 0.9125 - val_loss: 0.5085 - val_categorical_accuracy: 0.8645\n",
      "Epoch 180/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2639 - categorical_accuracy: 0.9119 - val_loss: 0.5321 - val_categorical_accuracy: 0.8650\n",
      "Epoch 181/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2628 - categorical_accuracy: 0.9117 - val_loss: 0.5514 - val_categorical_accuracy: 0.8650\n",
      "Epoch 182/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2632 - categorical_accuracy: 0.9115 - val_loss: 0.4995 - val_categorical_accuracy: 0.8645\n",
      "Epoch 183/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2637 - categorical_accuracy: 0.9104 - val_loss: 0.4680 - val_categorical_accuracy: 0.8675\n",
      "Epoch 184/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2680 - categorical_accuracy: 0.9096 - val_loss: 0.5188 - val_categorical_accuracy: 0.8660\n",
      "Epoch 185/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2642 - categorical_accuracy: 0.9112 - val_loss: 0.5107 - val_categorical_accuracy: 0.8650\n",
      "Epoch 186/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2630 - categorical_accuracy: 0.9110 - val_loss: 0.5268 - val_categorical_accuracy: 0.8645\n",
      "Epoch 187/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2621 - categorical_accuracy: 0.9122 - val_loss: 0.5246 - val_categorical_accuracy: 0.8640\n",
      "Epoch 188/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2630 - categorical_accuracy: 0.9128 - val_loss: 0.5167 - val_categorical_accuracy: 0.8640\n",
      "Epoch 189/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2620 - categorical_accuracy: 0.9137 - val_loss: 0.5102 - val_categorical_accuracy: 0.8625\n",
      "Epoch 190/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2609 - categorical_accuracy: 0.9145 - val_loss: 0.5391 - val_categorical_accuracy: 0.8630\n",
      "Epoch 191/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2618 - categorical_accuracy: 0.9132 - val_loss: 0.5339 - val_categorical_accuracy: 0.8615\n",
      "Epoch 192/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2603 - categorical_accuracy: 0.9130 - val_loss: 0.4868 - val_categorical_accuracy: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2633 - categorical_accuracy: 0.9123 - val_loss: 0.5080 - val_categorical_accuracy: 0.8640\n",
      "Epoch 194/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2638 - categorical_accuracy: 0.9112 - val_loss: 0.5084 - val_categorical_accuracy: 0.8640\n",
      "Epoch 195/200\n",
      "2780/2780 [==============================] - 7s 2ms/step - loss: 0.2628 - categorical_accuracy: 0.9119 - val_loss: 0.5184 - val_categorical_accuracy: 0.8640\n",
      "Epoch 196/200\n",
      "2780/2780 [==============================] - 8s 3ms/step - loss: 0.2630 - categorical_accuracy: 0.9125 - val_loss: 0.5246 - val_categorical_accuracy: 0.8645\n",
      "Epoch 197/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2630 - categorical_accuracy: 0.9127 - val_loss: 0.5074 - val_categorical_accuracy: 0.8645\n",
      "Epoch 198/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2628 - categorical_accuracy: 0.9119 - val_loss: 0.5175 - val_categorical_accuracy: 0.8630\n",
      "Epoch 199/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2615 - categorical_accuracy: 0.9140 - val_loss: 0.5102 - val_categorical_accuracy: 0.8640\n",
      "Epoch 200/200\n",
      "2780/2780 [==============================] - 6s 2ms/step - loss: 0.2613 - categorical_accuracy: 0.9138 - val_loss: 0.4967 - val_categorical_accuracy: 0.8640\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(shuffle_x_train),\n",
    "                    np.array(shuffle_target),\n",
    "                    epochs=200,\n",
    "                   validation_data = (np.array([x_train_set[i:i+100] for i in range(139000,140000,50)]),\n",
    "                     np.array([target_onehot[i:i+100] for i in range(139000,140000,50)])),\n",
    "    batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(np.array(x_test_set[:34400]).reshape(172,200,3))\n",
    "results = results.reshape(34400,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140532"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_set) + len(x_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68055487, 0.18456206, 0.134883  ],\n",
       "       [0.8326388 , 0.10047033, 0.06689084],\n",
       "       [0.90336925, 0.0612621 , 0.0353686 ],\n",
       "       ...,\n",
       "       [0.994238  , 0.00386085, 0.00190116],\n",
       "       [0.99424654, 0.00385065, 0.00190275],\n",
       "       [0.99425405, 0.00384028, 0.00190558]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_class = []\n",
    "for i in results:\n",
    "    if(np.argmax(i)==0):\n",
    "        result_class.append(0)\n",
    "    elif(np.argmax(i)==1):\n",
    "        result_class.append(1)\n",
    "    elif(np.argmax(i)==2):\n",
    "        result_class.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - acceleration event, duration: 1.24  tsteps init: 8075 end: 8198\n",
      "1 - acceleration event, duration: 1.1  tsteps init: 11471 end: 11580\n",
      "2 - acceleration event, duration: 1.43  tsteps init: 12056 end: 12198\n",
      "3 - acceleration event, duration: 1.89  tsteps init: 23210 end: 23398\n",
      "4 - braking event, duration: 0.54  tsteps init: 23690 end: 23743\n",
      "5 - braking event, duration: 2.06  tsteps init: 26593 end: 26798\n",
      "6 - braking event, duration: 0.67  tsteps init: 29629 end: 29695\n",
      "7 - braking event, duration: 0.75  tsteps init: 30324 end: 30398\n",
      "8 - acceleration event, duration: 1.63  tsteps init: 30636 end: 30798\n",
      "9 - braking event, duration: 1.87  tsteps init: 31005 end: 31191\n",
      "10 - acceleration event, duration: 0.98  tsteps init: 31501 end: 31598\n",
      "11 - braking event, duration: 0.81  tsteps init: 32647 end: 32727\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating list of events and \n",
    "removing events with duration lower than 50\n",
    "\n",
    "Event tuple: [type, duration]\n",
    "UPDATED:\n",
    "\n",
    "Event tuple : [type, init-point, end-point, duration, energy/duration(sec)]\n",
    "UPDATED:\n",
    "Event tuple : [type, init-point, end-point, duration, energy/duration(sec), mean(3-max value)]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "brks = 0\n",
    "accs = 0\n",
    "num_events = 0\n",
    "events = []\n",
    "freq = 100 \n",
    "\n",
    "for i in range(len(result_class)):\n",
    "    if(result_class[i]==1):\n",
    "        brks += 1\n",
    "    elif(result_class[i]==2):\n",
    "        accs += 1\n",
    "    else:\n",
    "        if(brks > 50):\n",
    "            events.append((\"brake\", i-brks, i-1, brks/freq))\n",
    "            print(num_events, \"- braking event,\" ,\"duration:\", brks/freq, \" tsteps\", \"init:\", i-brks ,\"end:\", i-1)\n",
    "            brks = 0\n",
    "            num_events += 1\n",
    "                  \n",
    "        elif(accs > 50):\n",
    "            events.append((\"acc\", i-accs, i-1, accs/freq))\n",
    "            print(num_events, \"- acceleration event,\" ,\"duration:\", accs/freq, \" tsteps\", \"init:\", i-accs ,\"end:\", i-1)\n",
    "            accs = 0\n",
    "            num_events += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - acceleration event, duration: 1.25  tsteps init: 8075 end: 8199\n",
      "1 - acceleration event, duration: 1.11  tsteps init: 11471 end: 11581\n",
      "2 - acceleration event, duration: 1.44  tsteps init: 12056 end: 12199\n",
      "3 - acceleration event, duration: 1.9  tsteps init: 23210 end: 23399\n",
      "4 - braking event, duration: 0.55  tsteps init: 23690 end: 23744\n",
      "5 - braking event, duration: 2.07  tsteps init: 26593 end: 26799\n",
      "6 - braking event, duration: 0.68  tsteps init: 29629 end: 29696\n",
      "7 - braking event, duration: 0.76  tsteps init: 30324 end: 30399\n",
      "8 - acceleration event, duration: 1.64  tsteps init: 30636 end: 30799\n",
      "9 - braking event, duration: 1.88  tsteps init: 31005 end: 31192\n",
      "10 - acceleration event, duration: 0.99  tsteps init: 31501 end: 31599\n",
      "11 - braking event, duration: 0.82  tsteps init: 32647 end: 32728\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating list of events and \n",
    "removing events with energy < 20 and duration lower than 30\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "brks = 0\n",
    "accs = 0\n",
    "num_events = 0\n",
    "events = []\n",
    "freq = 100 \n",
    "scaled_x_test = Scale(x_test_set)\n",
    "\n",
    "for i in range(len(result_class)):\n",
    "    if(result_class[i]==1):\n",
    "        brks += 1\n",
    "    elif(result_class[i]==2):\n",
    "        accs += 1\n",
    "    else:\n",
    "        if(brks > 50 ):\n",
    "            signal = [abs ((scaled_x_test)[i][0]) for i in range(i-brks, i-1)]\n",
    "            energy = Energy(signal)\n",
    "            if(energy > 10):\n",
    "                events.append((\"brake\", i-brks, i-1, brks/freq))\n",
    "                print(num_events, \"- braking event,\" ,\"duration:\", brks/freq, \" tsteps\", \"init:\", i-brks ,\"end:\", i-1)\n",
    "                num_events += 1\n",
    "            brks = 0\n",
    "        elif(accs > 50):\n",
    "            signal = [abs ((scaled_x_test)[i][0]) for i in range(i-accs, i-1)]\n",
    "            energy = Energy(signal)\n",
    "            if(energy > 10):\n",
    "                events.append((\"acc\", i-accs, i-1, accs/freq))\n",
    "                print(num_events, \"- acceleration event,\" ,\"duration:\", accs/freq, \" tsteps\", \"init:\", i-accs ,\"end:\", i-1)\n",
    "                num_events += 1\n",
    "            accs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assign intensity to each event \n",
    "0, 1, 2 --> Low, Medium, High\n",
    "thresholds:\n",
    "    0.98\n",
    "    1.96\n",
    "    3.92\n",
    "\"\"\"    \n",
    "i = 0\n",
    "scaled_x_test = Scale(x_test_set)\n",
    "for e in events:\n",
    "    event_type, init, end, duration = e\n",
    "    signal = [abs(scaled_x_test)[i][0] for i in range(init, end)]\n",
    "    events[i] += (ComputeIntensity(signal),)\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_class = np.zeros(len(x_test_set))\n",
    "for e in events:\n",
    "    event_type, init, end, duration, intensity = e\n",
    "    if(event_type ==\"brake\"):\n",
    "        result_class[init:end] = 1\n",
    "    elif(event_type==\"acc\"):\n",
    "        result_class[init:end] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeIntensity(signal):\n",
    "    max_values = np.mean(nlargest(3, signal))\n",
    "    if(max_values > 0.98 and max_values < 1.96):\n",
    "        return 0\n",
    "    elif(max_values > 1.96 and max_values< 3.92):\n",
    "        return 1\n",
    "    elif(max_values > 3.92):\n",
    "        return 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computing the energy (on x-axis)\n",
    "First, scale the accelerometer signal to the 9.8 \n",
    "Second, iterate list of events, calculate energy of the x-axis \n",
    "\"\"\"\n",
    "\n",
    "def Energy(data):\n",
    "    data = [abs(number) for number in data]\n",
    "    return np.sum(np.power(data,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "k-max value\n",
    "mean of the k max value \n",
    "\"\"\"\n",
    "\n",
    "i = 0\n",
    "for e in events:\n",
    "    event_type, init, end, duration, _ = e\n",
    "    signal = [abs(scaled_x_test[i][0]) for i in range(init, end)]\n",
    "    print(event_type, np.mean(nlargest(3, signal)))\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scaling signal to m/s2\n",
    "\"\"\"\n",
    "def Scale(data):\n",
    "    scaled_x_test = data.copy()\n",
    "    for i in range(len(scaled_x_test)):\n",
    "        for j in range(len(scaled_x_test[0])):\n",
    "            scaled_x_test[i][j] = scaled_x_test[i][j] * 9.8\n",
    "    return scaled_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding energy, max-values attr\n",
    "\"\"\"\n",
    "\n",
    "i = 0\n",
    "for e in events:\n",
    "    event_type, init, end, duration = e\n",
    "    signal = [abs (scaled_x_test[i][0]) for i in range(init, end)]\n",
    "    events[i] += (Energy(signal),)\n",
    "    events[i] += (np.mean(nlargest(3, signal)),)\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.2395899392445\n",
      "9.350331882106548\n",
      "17.11265124272187\n",
      "32.10789721846348\n",
      "31.959289845960992\n"
     ]
    }
   ],
   "source": [
    "scaled_x_train = x_train_set.copy()\n",
    "for i in range(len(scaled_x_train)):\n",
    "    for j in range(len(scaled_x_train[0])):\n",
    "        scaled_x_train[i][j] = scaled_x_train[i][j] * 9.8\n",
    "\n",
    "\n",
    "print(Energy(scaled_x_test[11027:11228])/2)\n",
    "print(Energy(scaled_x_train[11634:11735])/2)\n",
    "print(Energy(scaled_x_train[13151:13454])/3)\n",
    "print(Energy(scaled_x_train[20838:21141])/3)\n",
    "print(Energy(scaled_x_train[21346:21546])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the energy for driverbehavior dataset 21 aggressive brake\n",
    "accLinear21 = pandas.read_csv('./data/21/aceleracaoLinear_terra.csv')\n",
    "groundTruth21 = pandas.read_csv('./data/21/groundTruthEdited.csv')\n",
    "\n",
    "accLinear21 = accLinear21[['x','y','z']]\n",
    "accLinear21 = np.array(accLinear21)\n",
    "accLinear21 = SmoothData(accLinear21)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653.6227058011023\n",
      "482.4623294334049\n",
      "481.1426101592832\n",
      "522.5912234803596\n",
      "152.52759937798353\n",
      "534.6667930646526\n",
      "41.06582885307229\n",
      "23.175237433004195\n"
     ]
    }
   ],
   "source": [
    "print(Energy(accLinear21[10105:10256])/(151/50))\n",
    "print(Energy(accLinear21[13059:13261])/4  )\n",
    "print(Energy(accLinear21[14689:14892])/4)\n",
    "print(Energy(accLinear21[16421:16573])/3)\n",
    "print(Energy(accLinear21[17287:17490])/4)\n",
    "print(Energy(accLinear21[19834:19986])/3)\n",
    "print(Energy(accLinear21[9595:9849])/5)\n",
    "print(Energy(accLinear21[1751:1954])/4)\n",
    "# print(np.mean(nlargest(3,[abs(accLinear21[i][0]) for i in range(10105,10256)])))\n",
    "# print(np.mean(nlargest(3,[abs(accLinear21[i][0]) for i in range(13059,13261)])))\n",
    "# print(np.mean(nlargest(3,[abs(accLinear21[i][0]) for i in range(14689,14892)])))\n",
    "# print(np.mean(nlargest(3,[abs(accLinear21[i][0]) for i in range(16421,16573)])))\n",
    "# print(np.mean(nlargest(3,[abs(accLinear21[i][0]) for i in range(17287,17490)])))\n",
    "# print(np.mean(nlargest(3,[abs(accLinear21[i][0]) for i in range(19834,19986)])))\n",
    "\n",
    "# print(Energy(accLinear21[13059:13261])/4)\n",
    "# print(Energy(accLinear21[14689:14892])/4)\n",
    "# print(Energy(accLinear21[16421:16573])/3)\n",
    "# print(Energy(accLinear21[17287:17490])/4)\n",
    "# print(Energy(accLinear21[19834:19986])/3)\n",
    "# print(Energy(accLinear21[9595:9849])/5)\n",
    "# print(Energy(accLinear21[1751:1954])/4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29619,   316,   270],\n",
       "       [ 1619,   354,     0],\n",
       "       [ 1692,     0,   557]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_test_set.copy()\n",
    "y_pred = result_class.copy()\n",
    "classes = [0,1,2]\n",
    "confusion_matrix(y_true, y_pred, labels=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evento</th>\n",
       "      <th>startIndexinAcc</th>\n",
       "      <th>endIndexinAcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>1751</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>troca_faixa_esquerda_agressiva</td>\n",
       "      <td>1140</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>4298</td>\n",
       "      <td>4552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>troca_faixa_esquerda_agressiva</td>\n",
       "      <td>4909</td>\n",
       "      <td>5112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>troca_faixa_esquerda_agressiva</td>\n",
       "      <td>5470</td>\n",
       "      <td>5622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>5928</td>\n",
       "      <td>6182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>troca_faixa_esquerda_agressiva</td>\n",
       "      <td>8271</td>\n",
       "      <td>8423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>9595</td>\n",
       "      <td>9849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>freada_agressiva</td>\n",
       "      <td>10105</td>\n",
       "      <td>10256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>freada_agressiva</td>\n",
       "      <td>13059</td>\n",
       "      <td>13261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>freada_agressiva</td>\n",
       "      <td>14689</td>\n",
       "      <td>14892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>freada_agressiva</td>\n",
       "      <td>16421</td>\n",
       "      <td>16573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>freada_agressiva</td>\n",
       "      <td>17287</td>\n",
       "      <td>17490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>freada_agressiva</td>\n",
       "      <td>19834</td>\n",
       "      <td>19986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>21617</td>\n",
       "      <td>21870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>24469</td>\n",
       "      <td>24774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>26150</td>\n",
       "      <td>26353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>28748</td>\n",
       "      <td>28900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>35626</td>\n",
       "      <td>35829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>36339</td>\n",
       "      <td>36542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>38224</td>\n",
       "      <td>38427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>39905</td>\n",
       "      <td>40108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            evento  startIndexinAcc  endIndexinAcc\n",
       "0             evento_nao_agressivo             1751           1954\n",
       "1   troca_faixa_esquerda_agressiva             1140           1241\n",
       "2             evento_nao_agressivo             4298           4552\n",
       "3   troca_faixa_esquerda_agressiva             4909           5112\n",
       "4   troca_faixa_esquerda_agressiva             5470           5622\n",
       "5             evento_nao_agressivo             5928           6182\n",
       "6   troca_faixa_esquerda_agressiva             8271           8423\n",
       "7             evento_nao_agressivo             9595           9849\n",
       "8                 freada_agressiva            10105          10256\n",
       "9                 freada_agressiva            13059          13261\n",
       "10                freada_agressiva            14689          14892\n",
       "11                freada_agressiva            16421          16573\n",
       "12                freada_agressiva            17287          17490\n",
       "13                freada_agressiva            19834          19986\n",
       "14            aceleracao_agressiva            21617          21870\n",
       "15            aceleracao_agressiva            24469          24774\n",
       "16            aceleracao_agressiva            26150          26353\n",
       "17            aceleracao_agressiva            28748          28900\n",
       "18            aceleracao_agressiva            35626          35829\n",
       "19            aceleracao_agressiva            36339          36542\n",
       "20            evento_nao_agressivo            38224          38427\n",
       "21            evento_nao_agressivo            39905          40108"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundTruth21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nima Tavassoli\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\plotly\\tools.py:465: DeprecationWarning:\n",
      "\n",
      "plotly.tools.make_subplots is deprecated, please use plotly.subplots.make_subplots instead\n",
      "\n",
      "C:\\Users\\Nima Tavassoli\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\plotly\\offline\\offline.py:563: UserWarning:\n",
      "\n",
      "Your filename `my_data_brake_acc_onehot_200_softmax_categorical_crossentropy` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my_data_brake_acc_onehot_200_softmax_categorical_crossentropy.html'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fig =tools.make_subplots(rows=1,cols=1)\n",
    "\n",
    "result =  go.Scatter(\n",
    "    x = list(range(0,34400)),\n",
    "    y = result_class,\n",
    "    mode = 'lines',\n",
    "    name='model_result'\n",
    ")\n",
    "\n",
    "test =  go.Scatter(\n",
    "    x = list(range(0,34400)),\n",
    "    y = y_test_set,\n",
    "    mode = 'lines',\n",
    "    name='test'\n",
    ")\n",
    "\n",
    "fig.append_trace(result,1,1)\n",
    "fig.append_trace(test,1,1)\n",
    "\n",
    "\n",
    "fig['layout'].update(height=500, title = 'Brake_Acc Model Classification')\n",
    "\n",
    "\n",
    "py.offline.plot(fig, filename='my_data_brake_acc_onehot_200_softmax_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acc', 2021, 2168, 1.48, 1),\n",
       " ('acc', 4094, 4199, 1.06, 0),\n",
       " ('acc', 5324, 5399, 0.76, 1),\n",
       " ('acc', 5421, 5599, 1.79, 1),\n",
       " ('acc', 5618, 5729, 1.12, 1),\n",
       " ('acc', 6796, 6999, 2.04, 1),\n",
       " ('acc', 7017, 7168, 1.52, 1),\n",
       " ('acc', 7949, 7999, 0.51, 1),\n",
       " ('acc', 8020, 8199, 1.8, 0),\n",
       " ('acc', 8244, 8365, 1.22, 0),\n",
       " ('acc', 13070, 13199, 1.3, 1),\n",
       " ('acc', 17992, 18199, 2.08, 1),\n",
       " ('brake', 18360, 18530, 1.71, 1),\n",
       " ('acc', 21449, 21599, 1.51, 0),\n",
       " ('acc', 21675, 21799, 1.25, 0),\n",
       " ('acc', 25275, 25360, 0.86, None),\n",
       " ('acc', 26616, 26794, 1.79, 1),\n",
       " ('acc', 27239, 27379, 1.41, 0)]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nima Tavassoli\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\plotly\\offline\\offline.py:563: UserWarning:\n",
      "\n",
      "Your filename `brake_acc_test_data` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'brake_acc_test_data.html'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# test = pandas.read_csv('./data/Learning/brake, acc/Test_Set.csv')\n",
    "test = pandas.read_csv('./data/Learning/MyData/version1/Test_Set.csv')\n",
    "\n",
    "\n",
    "fig =tools.make_subplots(rows=1,cols=1)\n",
    "\n",
    "\n",
    "test =  go.Scatter(\n",
    "    x = list(range(0,27100)),\n",
    "    y = test['x'],\n",
    "    mode = 'lines',\n",
    "    name='test'\n",
    ")\n",
    "\n",
    "fig.append_trace(test,1,1)\n",
    "\n",
    "\n",
    "fig['layout'].update(height=500, title = 'Test Data')\n",
    "\n",
    "\n",
    "py.offline.plot(fig, filename='brake_acc_test_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nima Tavassoli\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\plotly\\offline\\offline.py:563: UserWarning:\n",
      "\n",
      "Your filename `multiple-axes-double` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'multiple-axes-double.html'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig =tools.make_subplots(rows=2,cols=1)\n",
    "\n",
    "loss_result =  go.Scatter(\n",
    "    x = list(range(0,500)),\n",
    "    y = history.history['loss'],\n",
    "    mode = 'lines'\n",
    ")\n",
    "\n",
    "acc_result =  go.Scatter(\n",
    "    x = list(range(0,500)),\n",
    "    y = history.history['categorical_accuracy'],\n",
    "    mode = 'lines'\n",
    ")\n",
    "\n",
    "fig.append_trace(loss_result, 1, 1)\n",
    "fig.append_trace(acc_result, 2, 1)\n",
    "\n",
    "fig['layout'].update(height=650, title = 'Loss, Accuracy')\n",
    "py.offline.plot(fig, filename='multiple-axes-double')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./Learning_model/version1/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./Learning_model/version1/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nima Tavassoli\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('./Learning_model/version1/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./Learning_model/version1/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "model = loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Log Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_part3 = pandas.read_csv('./MyData/22.4.2020.part3.csv')\n",
    "my_data_part2 = pandas.read_csv('./MyData/22.4.2020.part2.csv')\n",
    "my_data_round1 = pandas.read_csv('./MyData/22.4.2020/round1.csv')\n",
    "my_data_round2 = pandas.read_csv('./MyData/22.4.2020/round2.csv')\n",
    "my_data_round3 = pandas.read_csv('./MyData/22.4.2020/round3.csv')\n",
    "\n",
    "\n",
    "# working_set = my_data[['accelerometerAccelerationX(G)','accelerometerAccelerationY(G)','accelerometerAccelerationZ(G)']][3200:3700]        \n",
    "\n",
    "set_user_part3 = my_data_part3[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']]\n",
    "set_user_part2 = my_data_part2[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']]\n",
    "set_user_round1 = my_data_round1[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']]\n",
    "set_user_round2 = my_data_round2[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']]\n",
    "set_user_round3 = my_data_round3[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']]\n",
    "\n",
    "######\n",
    "\n",
    "my_data_brake_round4 = pandas.read_csv('./MyData/24.4.2020/brake_round4.csv')\n",
    "my_data_brake_round5 = pandas.read_csv('./MyData/24.4.2020/brake_round5.csv')\n",
    "\n",
    "set_user_brake_round4 = my_data_brake_round4[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']]\n",
    "set_user_brake_round5 = my_data_brake_round5[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RenderData(data, fig, init, end):\n",
    "    acx =  go.Scatter(\n",
    "        x = list(range(init, end)),\n",
    "        y = [data[i][0] for i in range(init, end)],\n",
    "        mode = 'lines',\n",
    "        name = 'x'\n",
    "    )\n",
    "    \n",
    "\n",
    "    acy =  go.Scatter(\n",
    "        x = list(range(init, end)),\n",
    "        y = [data[i][1] for i in range(init, end)],\n",
    "        mode = 'lines',\n",
    "        name='y'\n",
    "    )\n",
    "\n",
    "    acz =  go.Scatter(\n",
    "        x = list(range(init, end)),\n",
    "        y = [data[i][2] for i in range(init, end)],\n",
    "        mode = 'lines',\n",
    "        name='z'\n",
    "    )\n",
    "    fig.append_trace(acx,1,1)\n",
    "    fig.append_trace(acy,1,1)\n",
    "    fig.append_trace(acz,1,1)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_user_part2 = np.array(set_user_part2)\n",
    "set_user_part2 = SmoothData(set_user_part2)\n",
    "set_user_part3 = np.array(set_user_part3)\n",
    "set_user_part3 = SmoothData(set_user_part3)\n",
    "######\n",
    "set_user_round1 = np.array(set_user_round1)\n",
    "set_user_round2 = np.array(set_user_round2)\n",
    "set_user_round3 = np.array(set_user_round3)\n",
    "set_user_round1 = SmoothData(set_user_round1)\n",
    "set_user_round2 = SmoothData(set_user_round2)\n",
    "set_user_round3 = SmoothData(set_user_round3)\n",
    "\n",
    "set_user_brake_round4 = np.array(set_user_brake_round4)\n",
    "set_user_brake_round5 = np.array(set_user_brake_round5)\n",
    "set_user_brake_round4 = SmoothData(set_user_brake_round4)\n",
    "set_user_brake_round5 = SmoothData(set_user_brake_round5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nima Tavassoli\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\plotly\\tools.py:465: DeprecationWarning:\n",
      "\n",
      "plotly.tools.make_subplots is deprecated, please use plotly.subplots.make_subplots instead\n",
      "\n",
      "C:\\Users\\Nima Tavassoli\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\plotly\\offline\\offline.py:563: UserWarning:\n",
      "\n",
      "Your filename `brake_acc_test_data` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'brake_acc_test_data.html'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig =tools.make_subplots(rows=1,cols=1)\n",
    "RenderData(set_user_round1, fig,  8093, 8395)\n",
    "fig['layout'].update(height=500, title = 'Test Data')\n",
    "py.offline.plot(fig, filename='brake_acc_test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47371"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_user_brake_round5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_env] *",
   "language": "python",
   "name": "conda-env-tensorflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
