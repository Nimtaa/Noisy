{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import pandas\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from matplotlib.pyplot import figure\n",
    "import random\n",
    "from heapq import nlargest\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Driving Inertial Signals \n",
    "Preprocess: Scale and Smoothing the signals \n",
    "Run 3 classifiers to detect Acc/Brake, RT/LT, UT \n",
    "Output: List of events with their intensities to analyse the driver's behavior\n",
    "\n",
    "\"\"\"\n",
    "### Driver 1\n",
    "# address = './MyData/22.4.2020.part2.csv'\n",
    "address = './MyData/22.4.2020.part3.csv'\n",
    "# address = './MyData/5.5.2020/2.5.2020 200505 16_40_37.csv'\n",
    "# address = './MyData/5.5.2020/2.5.2020 200505 17_12_00.csv'\n",
    "\n",
    "###Driver 2\n",
    "# address = './MyData/7.5.2020/2.5.2020 200507 19_44_25.csv'\n",
    "# address = './MyData/7.5.2020/2.5.2020 200507 19_58_41.csv'\n",
    "\n",
    "###Driver 3\n",
    "# address = './MyData/7.5.2020/2.5.2020 200508 00_40_14.csv'\n",
    "# address = './MyData/7.5.2020/2.5.2020 200508 00_19_22.csv'\n",
    "\n",
    "## Test Data\n",
    "# address = './data/Learning/Aggressive_from_jair/21.csv'\n",
    "# address = './data/Learning/Aggressive_from_jair/round5_labeled.csv'\n",
    "\n",
    "# address = './MyData/old_one.csv'\n",
    "# address = './MyData/2.5.2020/round6.csv'\n",
    "\n",
    "data = pandas.read_csv(address,  usecols=[8,23,24,25,15,16,17,29,30,31])\n",
    "# data = pandas.read_csv(address)\n",
    "\n",
    "X_turn = data\n",
    "X_acc = data[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc = load_model_acc()\n",
    "model_turn = load_model_turn()\n",
    "model_uturn = load_model_uturn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc = np.array(X_acc)\n",
    "X_acc = SmoothData(X_acc)\n",
    "X_turn = np.array(X_turn)\n",
    "X_turn = SmoothData(X_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = len(X_acc) - (len(X_acc) % 200)\n",
    "### Run the model based on input shape \n",
    "results_acc = model_acc.predict(np.array(X_acc[:section]).reshape(int(section/200),200,3))\n",
    "results_acc = results_acc.reshape(section,3)\n",
    "\n",
    "results_turn = model_turn.predict(np.array(X_turn[:section]).reshape(int(section/200),200,10))\n",
    "results_turn = results_turn.reshape(section,3)\n",
    "\n",
    "results_uturn = model_uturn.predict(np.array(X_turn[:section]).reshape(int(section/200),200,10))\n",
    "results_uturn = results_uturn.reshape(section,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### giving data to the create_turn_event\n",
    "\n",
    "events_turn = create_turn_event(X_turn[:section], one_hot_decode(results_turn))\n",
    "events_turn = assign_intensity_turn(events_turn, X_turn[:section])\n",
    "events_turn, deletion_index = merge_turn(events_turn)\n",
    "events_turn.remove(('',math.inf,math.inf,math.inf))\n",
    "del events_turn[0:max(deletion_index[-1])+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### giving acceleration data to the create_acc_event\n",
    "\n",
    "events_acc = create_acc_event(X_acc[:section], one_hot_decode(results_acc))\n",
    "events_acc = assign_intensity_acc(events_acc, X_acc[:section])\n",
    "events_acc, deletion_index = merge_acc(events_acc)\n",
    "events_acc.remove(('',math.inf,math.inf,math.inf))\n",
    "del events_acc[0:max(deletion_index[-1])+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### giving acceleration data to the create_uturn_event\n",
    "\n",
    "events_uturn = create_uturn_event(X_turn[:section], one_hot_uturn_decode(results_uturn))\n",
    "events_uturn = assign_intensity_turn(events_uturn, X_turn[:section])\n",
    "events_uturn, deletion_index = merge_uturn(events_uturn)\n",
    "events_uturn.remove(('',math.inf,math.inf,math.inf))\n",
    "del events_uturn[0:max(deletion_index[-1])+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge all events together\n",
    "\"\"\"\n",
    "all_events = []\n",
    "all_events += events_acc\n",
    "all_events += events_turn\n",
    "all_events += events_uturn\n",
    "\n",
    "all_events.sort(key=lambda tup: tup[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the score of driving\n",
    "E = (k1*Low + k2*Medium + k3*High) / duration\n",
    "\"\"\"\n",
    "\n",
    "def score_calc(data):\n",
    "    score = 0\n",
    "    init = data[0][1]\n",
    "    end = data[-1][2]\n",
    "    freq = 50\n",
    "    duration = (end - init) /freq\n",
    "    print(\"duration:\",(end-init)/freq)\n",
    "    for i in data:\n",
    "        if(i[4]==0):\n",
    "            score += 1\n",
    "        elif(i[4]==1):\n",
    "            score += 2\n",
    "        elif(i[4]==2):\n",
    "            score += 4\n",
    "    print(\"score\", score)\n",
    "    return score/duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDF (data, x):\n",
    "    count = 0\n",
    "    for i in data:\n",
    "        if(x >= i):\n",
    "            count +=1\n",
    "    return count/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in all_scores:\n",
    "    scores.append(1- CDF(data, i))\n",
    "print(\"Score per time unit:\", scores)\n",
    "print(\"Mean Score:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract information from events \n",
    "\"\"\"\n",
    "\n",
    "acc_df = pandas.DataFrame(events_acc)\n",
    "turn_df = pandas.DataFrame(events_turn)\n",
    "uturn_df = pandas.DataFrame(events_uturn)\n",
    "\n",
    "if(len(acc_df)):\n",
    "    acc_dist = np.array(acc_df.groupby([4]).size())\n",
    "else:\n",
    "    acc_dist = np.array([0,0,0])\n",
    "\n",
    "if(len(turn_df)):\n",
    "    turn_dist = np.array(turn_df.groupby([4]).size())\n",
    "else :\n",
    "    turn_dist = np.array([0,0,0])\n",
    "    \n",
    "if(len(uturn_df)):\n",
    "    uturn_dist = np.array(uturn_df.groupby([4]).size())\n",
    "else:\n",
    "    uturn_dist = np.array([0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_decode(results):\n",
    "    result_class = []\n",
    "    for i in results:\n",
    "        if(np.argmax(i)==0):\n",
    "            result_class.append(0)\n",
    "        elif(np.argmax(i)==1):\n",
    "            result_class.append(1)\n",
    "        elif(np.argmax(i)==2):\n",
    "            result_class.append(2)\n",
    "    return result_class\n",
    "\n",
    "def one_hot_uturn_decode(results):\n",
    "    result_class = []\n",
    "    for i in results:\n",
    "        if(np.argmax(i)==0):\n",
    "            result_class.append(0)\n",
    "        else:\n",
    "            result_class.append(1)\n",
    "    return result_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SmoothData(data):\n",
    "    size = data.shape[0] \n",
    "    dim = data.shape[1]\n",
    "    \n",
    "    smooth_data = np.zeros((size,dim))\n",
    "    \n",
    "    smooth_data[0] = data[0]\n",
    "    smooth_data[1] = data[1]\n",
    "    smooth_data[size-1] = data[size-1]\n",
    "    smooth_data[size-2] = data[size-2]\n",
    "    \n",
    "    for i in range(2, size-2):\n",
    "        smooth_data[i] = np.average([data[i], data[i-1], data[i+1]], axis=0)\n",
    "    return smooth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SmoothData(data):\n",
    "    size = data.shape[0] \n",
    "    dim = data.shape[1]\n",
    "    \n",
    "    smooth_data = np.zeros((size,dim))\n",
    "    \n",
    "    smooth_data[0] = data[0]\n",
    "    smooth_data[1] = data[1]\n",
    "    smooth_data[size-1] = data[size-1]\n",
    "    smooth_data[size-2] = data[size-2]\n",
    "    \n",
    "    for i in range(2, size-2):\n",
    "        smooth_data[i] = np.average([data[i], data[i-1], data[i+1]], axis=0)\n",
    "    return smooth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utitlity Functions\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Computing the energy (on y-axis)\n",
    "\n",
    "First, scale the accelerometer signal to the 9.8 \n",
    "Second, iterate list of events, calculate energy of the y-axis \n",
    "\"\"\"\n",
    "\n",
    "def Energy(data):\n",
    "    data = [abs(number) for number in data]\n",
    "    return np.sum(np.power(data,2))\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Scaling turn signal to m/s2\n",
    "\"\"\"\n",
    "def Scale(data):\n",
    "    scaled_data = data.copy()\n",
    "    for i in range(len(scaled_data)):\n",
    "        scaled_data[i] = scaled_data[i] * 9.8\n",
    "    return scaled_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating list of events and \n",
    "removing events with energy < 20 and duration lower than 50\n",
    "\n",
    "\"\"\"\n",
    "def create_acc_event(data, result_class):\n",
    "    \n",
    "    brks = 0\n",
    "    accs = 0\n",
    "    num_events = 0\n",
    "    events = []\n",
    "    freq = 100     \n",
    "    scaled_data = Scale([data[i][0] for i in range(len(data))]) # ax\n",
    "    for i in range(len(result_class)):\n",
    "        if(result_class[i]==1):\n",
    "            brks += 1\n",
    "        elif(result_class[i]==2):\n",
    "            accs += 1\n",
    "        else:\n",
    "            if(brks > 50 ):\n",
    "                signal = [abs ((scaled_data)[i]) for i in range(i-brks, i-1)]\n",
    "                energy = Energy(signal)\n",
    "                if(energy > 10):\n",
    "                    events.append((\"brake\", i-brks, i-1, brks/freq))\n",
    "                    num_events += 1\n",
    "                brks = 0\n",
    "            elif(accs > 50):\n",
    "                signal = [abs ((scaled_data)[i]) for i in range(i-accs, i-1)]\n",
    "                energy = Energy(signal)\n",
    "                if(energy > 10):\n",
    "                    events.append((\"acc\", i-accs, i-1, accs/freq))\n",
    "                    num_events += 1\n",
    "                accs = 0\n",
    "            \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_turn_event(data, result_class):\n",
    "    rt = 0\n",
    "    lt = 0\n",
    "    num_events = 0\n",
    "    num_rt = 0\n",
    "    num_lt = 0\n",
    "    events = []\n",
    "    freq = 100 \n",
    "    scaled_data = Scale([data[i][8] for i in range(len(data))]) # ay\n",
    "\n",
    "    for i in range(len(result_class)):\n",
    "        if(result_class[i]==1):\n",
    "            rt += 1\n",
    "        elif(result_class[i]==2):\n",
    "            lt += 1\n",
    "        else:\n",
    "            if(rt > 100 ):\n",
    "                signal = [abs ((scaled_data)[i]) for i in range(i-rt, i-1)]\n",
    "                energy = Energy(signal)\n",
    "                if(energy > 10):\n",
    "                    events.append((\"rt\", i-rt, i-1, rt/freq))\n",
    "                    num_events += 1\n",
    "                rt = 0\n",
    "            elif(lt > 100):\n",
    "                signal = [abs ((scaled_data)[i]) for i in range(i-lt, i-1)]\n",
    "                energy = Energy(signal)\n",
    "                if(energy > 10):\n",
    "                    events.append((\"lt\", i-lt, i-1, lt/freq))\n",
    "                    num_events += 1\n",
    "                lt = 0\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uturn_event(data, result_class):\n",
    "    ut = 0\n",
    "    num_events = 0\n",
    "    events = []\n",
    "    freq = 100 \n",
    "    scaled_data = Scale([data[i][8] for i in range(len(data))]) # ay\n",
    "\n",
    "    for i in range(len(result_class)):\n",
    "        if(result_class[i]==1):\n",
    "            ut += 1\n",
    "        else:\n",
    "            if(ut > 100):\n",
    "                signal = [abs ((scaled_data)[i]) for i in range(i-ut, i-1)]\n",
    "                energy = Energy(signal)\n",
    "                if(energy > 10):\n",
    "                    events.append((\"ut\", i-ut, i-1, ut/freq))\n",
    "#                     print(num_events, \"- ut event,\" ,\"duration:\", ut/freq, \" tsteps\", \"init:\", i-ut ,\"end:\", i-1)\n",
    "                    num_events += 1\n",
    "                ut = 0\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeIntensity(signal):\n",
    "    max_values = np.mean(nlargest(3, signal))\n",
    "    if(max_values > 0.08 and max_values < 0.2):\n",
    "        return 0\n",
    "    elif(max_values > 0.2 and max_values< 0.4):\n",
    "        return 1\n",
    "    elif(max_values > 0.4):\n",
    "        return 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assign intensity to each event \n",
    "0, 1, 2 --> Low, Medium, High\n",
    "thresholds:\n",
    "    0.98 = 0.1G\n",
    "    1.96 = 0.2G\n",
    "    3.92 = 0.4G\n",
    "\"\"\"    \n",
    "def assign_intensity_acc(events, data):\n",
    "    i = 0\n",
    "    for e in events:\n",
    "        event_type, init, end, duration = e\n",
    "        signal = [abs(data)[i][0] for i in range(init, end)]\n",
    "        events[i] += (ComputeIntensity(signal),)\n",
    "        i +=1\n",
    "    return events\n",
    "\n",
    "def assign_intensity_turn(events, data):\n",
    "    i = 0\n",
    "    for e in events:\n",
    "        event_type, init, end, duration = e\n",
    "        signal = [abs(data)[i][8] for i in range(init, end)]\n",
    "        events[i] += (ComputeIntensity(signal),)\n",
    "        i +=1\n",
    "    return events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "merging neighbour events\n",
    "Input: events\n",
    "Output: (merge acc neighbour events, deletion index)\n",
    "\"\"\"\n",
    "def merge_acc(events):    \n",
    "    duration = 0\n",
    "    merge_index = 0\n",
    "    deletion_index = []\n",
    "    events.append(('',math.inf,math.inf,math.inf))\n",
    "\n",
    "    for i in range(0,len(events)-1):\n",
    "        if(abs((events[i][2])-(events[i+1][1]))<11 and events[i][0]==events[i+1][0]):\n",
    "            duration +=1\n",
    "        else:\n",
    "            init = events[i-duration][1]\n",
    "            end = events[i][2]-1\n",
    "            events.append((events[i-duration][0], init, end, end-init, events[i-duration][4]))\n",
    "            deletion_index.append(np.arange(i-duration,i+1))\n",
    "            duration = 0\n",
    "    return (events, deletion_index)\n",
    "\n",
    "def merge_turn(events):    \n",
    "    duration = 0\n",
    "    merge_index = 0\n",
    "    deletion_index = []\n",
    "    events.append(('',math.inf,math.inf,math.inf))\n",
    "\n",
    "    for i in range(0,len(events)-1):\n",
    "        if(abs((events[i][2])-(events[i+1][1]))<11 and events[i][0]==events[i+1][0]):\n",
    "            duration +=1\n",
    "        else:\n",
    "            init = events[i-duration][1]\n",
    "            end = events[i][2]-1\n",
    "            events.append((events[i-duration][0], init, end, end-init, events[i-duration][4]))\n",
    "            deletion_index.append(np.arange(i-duration,i+1))\n",
    "            duration = 0\n",
    "    return (events, deletion_index)\n",
    "\n",
    "\n",
    "def merge_uturn(events):\n",
    "    duration = 0\n",
    "    merge_index = 0\n",
    "    deletion_index = []\n",
    "    events.append(('',math.inf,math.inf,math.inf))\n",
    "\n",
    "    for i in range(0,len(events)-1):\n",
    "        if(abs((events[i][2])-(events[i+1][1]))<11 and events[i][0]==events[i+1][0]):\n",
    "            duration +=1\n",
    "        else:\n",
    "            init = events[i-duration][1]\n",
    "            end = events[i][2]-1\n",
    "            events.append((events[i-duration][0], init, end, end-init, events[i-duration][4]))\n",
    "            deletion_index.append(np.arange(i-duration,i+1))\n",
    "            duration = 0\n",
    "    return (events, deletion_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "\"\"\"\n",
    "Output: Acc/Brake detection model\n",
    "\"\"\"\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "def load_model_acc():\n",
    "    json_file = open('./Learning_model/acc,brake/v2/model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"./Learning_model/acc,brake/v2/model.h5\")\n",
    "    print(\"Loaded model_acc from disk\")\n",
    "    model = loaded_model\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_turn():\n",
    "    json_file = open('./Learning_model/Turning/rt_lt_cv/v2/model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"./Learning_model/Turning/rt_lt_cv/v2/model.h5\")\n",
    "    print(\"Loaded model_turn from disk\")\n",
    "    model = loaded_model\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_uturn():\n",
    "    json_file = open('./Learning_model/Turning/ut_cv/model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"./Learning_model/Turning/ut_cv/model.h5\")\n",
    "    print(\"Loaded model_uturn from disk\")\n",
    "    model = loaded_model\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_env] *",
   "language": "python",
   "name": "conda-env-tensorflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
